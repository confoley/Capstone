{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# procesando un chingo de la idioma natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "# NLP Tools\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy as sp\n",
    "from textblob import TextBlob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = pd.read_csv('./datasets/jun20_bb_posts.csv', )\n",
    "cnn = pd.read_csv('./datasets/jun20_cnn_posts.csv')\n",
    "fox = pd.read_csv('./datasets/jun20_fox_posts.csv')\n",
    "fox2 = pd.read_csv('./datasets/fox_posts_jun26.csv')\n",
    "fox3 = pd.read_csv('./datasets/fox_posts_jun29.csv')\n",
    "nr = pd.read_csv('./datasets/jun20_nr_posts.csv')\n",
    "nr2 = pd.read_csv('./datasets/jun29_nr_posts.csv')\n",
    "# nyt = pd.read_csv('./datasets/jun20_nyt_posts.csv')\n",
    "vice = pd.read_csv('./datasets/jun20_vice_posts.csv')\n",
    "dem = pd.read_csv('./datasets/jun21_demnow_posts.csv')\n",
    "dem2 = pd.read_csv('./datasets/jun22_demnow_posts.csv')\n",
    "dem3 = pd.read_csv('./datasets/jun23_demnow_posts.csv')\n",
    "dem4 = pd.read_csv('./datasets/jun24_demnow_posts.csv')\n",
    "dem5 = pd.read_csv('./datasets/jun25_demnow_posts.csv')\n",
    "dem6 = pd.read_csv('./datasets/jun26_demnow_posts.csv')\n",
    "dem7 = pd.read_csv('./datasets/jun29_demnow_posts.csv')\n",
    "inwa = pd.read_csv('./datasets/june20infowars.csv')\n",
    "inwa2 = pd.read_csv('./datasets/june21infowars.csv')\n",
    "inwa3 = pd.read_csv('./datasets/june22infowars.csv')\n",
    "inwa4 = pd.read_csv('./datasets/june23infowars.csv')\n",
    "inwa5 = pd.read_csv('./datasets/june24infowars.csv')\n",
    "inwa6 = pd.read_csv('./datasets/june25infowars.csv')\n",
    "inwa7 = pd.read_csv('./datasets/june26infowars.csv')\n",
    "inwa8 = pd.read_csv('./datasets/june29infowars.csv')\n",
    "msnbc = pd.read_csv('./datasets/jun26_msnbc_posts.csv')\n",
    "huff = pd.read_csv('./datasets/jun_24_huff_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb['yes_right'] = 1\n",
    "cnn['yes_right'] = 0\n",
    "fox['yes_right'] = 1\n",
    "fox2['yes_right'] = 1\n",
    "fox3['yes_right'] = 1\n",
    "nr['yes_right'] = 1\n",
    "nr2['yes_right'] = 1\n",
    "# nyt['yes_right'] = 0\n",
    "vice['yes_right'] = 0\n",
    "dem['yes_right'] = 0\n",
    "dem2['yes_right'] = 0\n",
    "dem3['yes_right'] = 0\n",
    "dem4['yes_right'] = 0\n",
    "dem5['yes_right'] = 0\n",
    "dem6['yes_right'] = 0\n",
    "dem7['yes_right'] = 0\n",
    "inwa['yes_right'] = 1\n",
    "inwa2['yes_right'] = 1\n",
    "inwa3['yes_right'] = 1\n",
    "inwa4['yes_right'] = 1\n",
    "inwa5['yes_right'] = 1\n",
    "inwa6['yes_right'] = 1\n",
    "inwa7['yes_right'] = 1\n",
    "inwa8['yes_right'] = 1\n",
    "msnbc['yes_right'] = 0\n",
    "huff['yes_right'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.concat(\n",
    "    [bb, cnn, fox, fox2, fox3, nr, nr2, vice, dem, dem2, dem3, dem4, dem5, dem6, dem7, inwa,\n",
    "     inwa2, inwa3, inwa4, inwa5, inwa6, inwa7, inwa8, msnbc, huff])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.drop(['Unnamed: 0', 'category', 'urlToImage'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author         9466\n",
       "description      69\n",
       "publishedAt       0\n",
       "source            0\n",
       "title             1\n",
       "url               0\n",
       "yes_right         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_desc = text.description.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.dropna(subset=['description','title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author         9408\n",
       "description       0\n",
       "publishedAt       0\n",
       "source            0\n",
       "title             0\n",
       "url               0\n",
       "yes_right         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.fillna('no_author', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50578, 7)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36854"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.url.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.drop_duplicates('url', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36854, 7)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4652954903131275"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.yes_right.value_counts()[1]/len(text.yes_right) #baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fox news           6381\n",
       "national review    5348\n",
       "huffington post    4950\n",
       "msnbc              4950\n",
       "vice news          4949\n",
       "breitbart          4948\n",
       "cnn                4776\n",
       "infowars            471\n",
       "democracy now        81\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dict = {'breitbart': \"Breitbart\", 'cnn': \"CNN\", 'fox news': \"Fox News\",\n",
    "               'national review': \"National Review\", 'vice news': \"Vice News\", 'democracy now': \"Democracy Now\",\n",
    "               'infowars': \"Infowars\", 'msnbc': \"MSNBC\", 'huffington post': \"Huffington Post\"}\n",
    "\n",
    "text['source'] = text['source'].map(source_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if statement, filter through text.values and append cleaned (or not) title to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in text.values:\n",
    "#     author = row[0]\n",
    "#     source = row[3]\n",
    "#     row[1] = row[1].replace(author, '')\n",
    "#     row[1] = row[1].replace(source, '')\n",
    "#     row[1] = row[1].replace(author.lower(), '')\n",
    "#     row[1] = row[1].replace(source.lower(), '')\n",
    "#     row[4] = row[1].replace(author, '')\n",
    "#     row[4] = row[1].replace(source, '')\n",
    "#     row[4] = row[1].replace(author.lower(), '')\n",
    "#     row[4] = row[1].replace(source.lower(), '')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize source and remove each word, remove each author\n",
    "\n",
    "# def remove_source_info(row):\n",
    "#     author = row[0]\n",
    "#     row[1] = row[1].replace(author, '')\n",
    "#     row[1] = row[1].replace(author.lower(), '')\n",
    "#     row[4] = row[1].replace(author, '')   \n",
    "#     row[4] = row[1].replace(author.lower(), '')\n",
    "#     source = row[3]\n",
    "#     row[1] = row[1].replace(source, '')\n",
    "#     row[1] = row[1].replace(source.lower(), '')\n",
    "#     row[4] = row[1].replace(source, '')   \n",
    "#     row[4] = row[1].replace(source.lower(), '')\n",
    "#     for n in tokenizer.tokenize(row[3]):\n",
    "#             row[1] = row[1].replace(n, '')\n",
    "#             row[1] = row[1].replace(n.lower(), '')\n",
    "#             row[4] = row[1].replace(n, '')\n",
    "#             row[4] = row[1].replace(n.lower(), '') \n",
    "#     return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['author'] = [a.replace(', CNN', '') for a in text['author']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_source_info(row):\n",
    "    sources = ['Breitbart', 'CNN', 'Fox News', 'National Review', 'Vice News', 'Democracy Now',\n",
    "               'Infowars', 'MSNBC', 'Huffington Post']\n",
    "    for source in sources:\n",
    "        row['description'] = row['description'].replace(source, '')\n",
    "        row['title'] = row['title'].replace(source, '')\n",
    "    row['title'] = row['title'].replace(row['author'], '')\n",
    "    row['description'] = row['description'].replace(row['author'], '')\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.apply(remove_source_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>description</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>yes_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>no_author</td>\n",
       "      <td>Judge Napolitano and Marie Harf discuss the Tr...</td>\n",
       "      <td>2018-06-20T18:51:36Z</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Freedom Watch: Napolitano and Harf dig in on i...</td>\n",
       "      <td>http://video.foxnews.com/v/5799861947001/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9725</th>\n",
       "      <td>no_author</td>\n",
       "      <td>Find out where and who caught a rare cotton ca...</td>\n",
       "      <td>2018-06-20T18:50:00Z</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>See it: Cotton candy-colored lobster caught</td>\n",
       "      <td>http://video.foxnews.com/v/5799865520001/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9726</th>\n",
       "      <td>no_author</td>\n",
       "      <td>Steve Harrigan reports from outside a detentio...</td>\n",
       "      <td>2018-06-20T18:47:58Z</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Media not given access to 'tender age' shelters</td>\n",
       "      <td>http://video.foxnews.com/v/5799862990001/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>no_author</td>\n",
       "      <td>Reports: More than 2,000 children have been se...</td>\n",
       "      <td>2018-06-20T18:47:54Z</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>Critics denounce 'tender age' shelters</td>\n",
       "      <td>http://video.foxnews.com/v/5799860019001/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9728</th>\n",
       "      <td>no_author</td>\n",
       "      <td>Nearly a year after the body of little boy was...</td>\n",
       "      <td>2018-06-20T18:38:34Z</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>‘Little Jacob’ has been identified</td>\n",
       "      <td>http://video.foxnews.com/v/5799856889001/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                        description  \\\n",
       "9724  no_author  Judge Napolitano and Marie Harf discuss the Tr...   \n",
       "9725  no_author  Find out where and who caught a rare cotton ca...   \n",
       "9726  no_author  Steve Harrigan reports from outside a detentio...   \n",
       "9727  no_author  Reports: More than 2,000 children have been se...   \n",
       "9728  no_author  Nearly a year after the body of little boy was...   \n",
       "\n",
       "               publishedAt    source  \\\n",
       "9724  2018-06-20T18:51:36Z  Fox News   \n",
       "9725  2018-06-20T18:50:00Z  Fox News   \n",
       "9726  2018-06-20T18:47:58Z  Fox News   \n",
       "9727  2018-06-20T18:47:54Z  Fox News   \n",
       "9728  2018-06-20T18:38:34Z  Fox News   \n",
       "\n",
       "                                                  title  \\\n",
       "9724  Freedom Watch: Napolitano and Harf dig in on i...   \n",
       "9725        See it: Cotton candy-colored lobster caught   \n",
       "9726    Media not given access to 'tender age' shelters   \n",
       "9727             Critics denounce 'tender age' shelters   \n",
       "9728                 ‘Little Jacob’ has been identified   \n",
       "\n",
       "                                            url  yes_right  \n",
       "9724  http://video.foxnews.com/v/5799861947001/          1  \n",
       "9725  http://video.foxnews.com/v/5799865520001/          1  \n",
       "9726  http://video.foxnews.com/v/5799862990001/          1  \n",
       "9727  http://video.foxnews.com/v/5799860019001/          1  \n",
       "9728  http://video.foxnews.com/v/5799856889001/          1  "
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.query(\"source=='Fox News'\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fox_news_clean(row):\n",
    "    \n",
    "#     if \"Fox News\" in row['description'][0:8]:\n",
    "#         row['description'] = row['description'][8:] \n",
    "        \n",
    "#     return row\n",
    "\n",
    "# #text.head(100).apply(fox_news_clean, axis=1)    \n",
    "# #text.query(\"source=='Breitbart'\").head(10)\n",
    "# text[text['description'].str.contains('Fox News 100')].head(10).apply(fox_news_clean, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['combined'] = text.title + ' ' + text.description # all text together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tokens = [tokenizer.tokenize(w) for w in text.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_word_length = []\n",
    "for title in title_tokens:\n",
    "    wordlen = []\n",
    "    for word in title:\n",
    "        wordlen.append(len(word))\n",
    "        if len(wordlen)==len(title):\n",
    "            avg_word_length.append(np.sum(wordlen)/len(wordlen))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36854"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['avg_word_len_title'] = avg_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['title_polarity'] = [TextBlob(w).sentiment.polarity for w in text.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['title_subjectivity'] = [TextBlob(w).sentiment.subjectivity for w in text.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['desc_polarity'] = [TextBlob(w).sentiment.polarity for w in text.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['desc_subjectivity'] = [TextBlob(w).sentiment.subjectivity for w in text.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['title_polarity'] = (text.title_polarity - min(text.title_polarity))/(max(text.title_polarity)-min(text.title_polarity))\n",
    "text['desc_polarity'] = (text.desc_polarity - min(text.desc_polarity))/(max(text.desc_polarity)-min(text.desc_polarity))\n",
    "# manual minmax scaler; i do not want negative values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['subj_difference'] = text['title_subjectivity'] - text['desc_subjectivity']\n",
    "text['polarity_difference']  = text['title_polarity'] - text['desc_polarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags = [TextBlob(w.lower(), tokenizer=tokenizer).tags for w in text.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('peter', 'NN'),\n",
       " ('fonda', 'NN'),\n",
       " ('lying', 'VBG'),\n",
       " ('gash', 'JJ'),\n",
       " ('kirstjen', 'NNS'),\n",
       " ('nielsen', 'VBN'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('whipped', 'VBN'),\n",
       " ('naked', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('public', 'JJ')]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_counts = []\n",
    "for row in title_tags:\n",
    "    tags = [n[1] for n in row]\n",
    "    tags_counts.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_parts_of_speech = []\n",
    "for n in tags_counts:\n",
    "    foo = dict(pd.Series(n).value_counts(normalize=True))\n",
    "    title_parts_of_speech.append(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_parts_of_speech = pd.DataFrame(title_parts_of_speech).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>MD</th>\n",
       "      <th>...</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CC   CD   DT   EX   FW        IN        JJ  JJR  JJS        MD ...   \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.083333  0.250000  0.0  0.0  0.083333 ...    \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.083333  0.250000  0.0  0.0  0.083333 ...    \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.000000  0.363636  0.0  0.0  0.000000 ...    \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.142857  0.142857  0.0  0.0  0.000000 ...    \n",
       "4  0.0  0.0  0.1  0.0  0.0  0.300000  0.100000  0.0  0.0  0.000000 ...    \n",
       "\n",
       "         VB  VBD       VBG       VBN  VBP  VBZ  WDT   WP  WP$  WRB  \n",
       "0  0.083333  0.0  0.083333  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.083333  0.0  0.083333  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.090909  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.285714  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.000000  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_parts_of_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14285714285714285,\n",
       " 0.29642857142857143,\n",
       " 1.4419413919413919,\n",
       " 1.711311787627577,\n",
       " 4.1597045927928278,\n",
       " 10.43336318394368,\n",
       " 12.412833408421644,\n",
       " 12.606152791137312,\n",
       " 21.882508510581268,\n",
       " 26.23270679550572]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([title_parts_of_speech[col].sum() for col in title_parts_of_speech.columns])[:10]\n",
    "# Any columns with negligible values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_parts_of_speech.columns = [str(n) + '_title' for n in title_parts_of_speech.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.342739</td>\n",
       "      <td>0.162052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJ_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.119757</td>\n",
       "      <td>0.104867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.096853</td>\n",
       "      <td>0.079797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNS_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.095445</td>\n",
       "      <td>0.100312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.045575</td>\n",
       "      <td>0.070313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean       std  min       25%       50%       75%  \\\n",
       "NN_title   36854.0  0.342739  0.162052  0.0  0.230769  0.333333  0.444444   \n",
       "JJ_title   36854.0  0.119757  0.104867  0.0  0.000000  0.111111  0.181818   \n",
       "IN_title   36854.0  0.096853  0.079797  0.0  0.000000  0.100000  0.142857   \n",
       "NNS_title  36854.0  0.095445  0.100312  0.0  0.000000  0.090909  0.153846   \n",
       "DT_title   36854.0  0.045575  0.070313  0.0  0.000000  0.000000  0.090909   \n",
       "\n",
       "                max  \n",
       "NN_title   1.000000  \n",
       "JJ_title   1.000000  \n",
       "IN_title   0.666667  \n",
       "NNS_title  1.000000  \n",
       "DT_title   0.500000  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_parts_of_speech.describe().T.sort_values('mean', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_tags = [TextBlob(w, tokenizer=tokenizer).tags for w in text.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_counts = []\n",
    "for row in desc_tags:\n",
    "    tags = [n[1] for n in row]\n",
    "    tags_counts.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_parts_of_speech = []\n",
    "for n in tags_counts:\n",
    "    foo = dict(pd.Series(n).value_counts(normalize=True))\n",
    "    desc_parts_of_speech.append(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_parts_of_speech = pd.DataFrame(desc_parts_of_speech).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>LS</th>\n",
       "      <th>...</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CC   CD        DT   EX   FW        IN        JJ  JJR       JJS   LS  \\\n",
       "0  0.000000  0.0  0.068182  0.0  0.0  0.090909  0.022727  0.0  0.000000  0.0   \n",
       "1  0.040000  0.0  0.000000  0.0  0.0  0.080000  0.080000  0.0  0.000000  0.0   \n",
       "2  0.040000  0.0  0.120000  0.0  0.0  0.100000  0.060000  0.0  0.000000  0.0   \n",
       "3  0.035714  0.0  0.107143  0.0  0.0  0.107143  0.142857  0.0  0.000000  0.0   \n",
       "4  0.000000  0.0  0.085714  0.0  0.0  0.114286  0.114286  0.0  0.028571  0.0   \n",
       "\n",
       "  ...         VB       VBD       VBG       VBN       VBP       VBZ  WDT  \\\n",
       "0 ...   0.022727  0.068182  0.045455  0.022727  0.000000  0.000000  0.0   \n",
       "1 ...   0.000000  0.000000  0.160000  0.040000  0.000000  0.040000  0.0   \n",
       "2 ...   0.080000  0.020000  0.060000  0.020000  0.100000  0.040000  0.0   \n",
       "3 ...   0.071429  0.035714  0.071429  0.000000  0.000000  0.035714  0.0   \n",
       "4 ...   0.000000  0.028571  0.057143  0.028571  0.057143  0.000000  0.0   \n",
       "\n",
       "         WP  WP$  WRB  \n",
       "0  0.022727  0.0  0.0  \n",
       "1  0.000000  0.0  0.0  \n",
       "2  0.000000  0.0  0.0  \n",
       "3  0.000000  0.0  0.0  \n",
       "4  0.000000  0.0  0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_parts_of_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_parts_of_speech.columns = [str(n) + '_desc' for n in desc_parts_of_speech.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_parts_of_speech.shape[0] == title_parts_of_speech.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = pd.concat([title_parts_of_speech, desc_parts_of_speech], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'description', 'publishedAt', 'source', 'title', 'url',\n",
       "       'yes_right', 'combined', 'avg_word_len_title', 'title_polarity',\n",
       "       'title_subjectivity', 'desc_polarity', 'desc_subjectivity',\n",
       "       'subj_difference', 'polarity_difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>desc_polarity</th>\n",
       "      <th>desc_subjectivity</th>\n",
       "      <th>subj_difference</th>\n",
       "      <th>polarity_difference</th>\n",
       "      <th>avg_word_len_title</th>\n",
       "      <th>CC_title</th>\n",
       "      <th>CD_title</th>\n",
       "      <th>DT_title</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD_desc</th>\n",
       "      <th>VBG_desc</th>\n",
       "      <th>VBN_desc</th>\n",
       "      <th>VBP_desc</th>\n",
       "      <th>VBZ_desc</th>\n",
       "      <th>WDT_desc</th>\n",
       "      <th>WP_desc</th>\n",
       "      <th>WP$_desc</th>\n",
       "      <th>WRB_desc</th>\n",
       "      <th>yes_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.555417</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.155417</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_polarity  title_subjectivity  desc_polarity  desc_subjectivity  \\\n",
       "0            0.50            0.233333       0.500000           0.000000   \n",
       "1            0.25            0.900000       0.250000           0.650000   \n",
       "2            0.40            0.300000       0.555417           0.666667   \n",
       "\n",
       "   subj_difference  polarity_difference  avg_word_len_title  CC_title  \\\n",
       "0         0.233333             0.000000            5.166667       0.0   \n",
       "1         0.250000             0.000000            5.750000       0.0   \n",
       "2        -0.366667            -0.155417            6.545455       0.0   \n",
       "\n",
       "   CD_title  DT_title    ...      VBD_desc  VBG_desc  VBN_desc  VBP_desc  \\\n",
       "0       0.0       0.0    ...      0.068182  0.045455  0.022727       0.0   \n",
       "1       0.0       0.0    ...      0.000000  0.160000  0.040000       0.0   \n",
       "2       0.0       0.0    ...      0.020000  0.060000  0.020000       0.1   \n",
       "\n",
       "   VBZ_desc  WDT_desc   WP_desc  WP$_desc  WRB_desc  yes_right  \n",
       "0      0.00       0.0  0.022727       0.0       0.0          1  \n",
       "1      0.04       0.0  0.000000       0.0       0.0          1  \n",
       "2      0.04       0.0  0.000000       0.0       0.0          1  \n",
       "\n",
       "[3 rows x 79 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([text[['title_polarity', 'title_subjectivity', 'desc_polarity', 'desc_subjectivity', \n",
    "                      'subj_difference', 'polarity_difference', 'avg_word_len_title']], pos_tags, text.yes_right],\n",
    "               axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subj_difference</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>-0.094585</td>\n",
       "      <td>0.383312</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.065054</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_difference</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>-0.015980</td>\n",
       "      <td>0.147941</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count      mean       std  min       25%       50%  \\\n",
       "subj_difference      36854.0 -0.094585  0.383312 -1.0 -0.350000 -0.041667   \n",
       "polarity_difference  36854.0 -0.015980  0.147941 -1.0 -0.083333  0.000000   \n",
       "\n",
       "                          75%  max  \n",
       "subj_difference      0.065054  1.0  \n",
       "polarity_difference  0.038194  0.9  "
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['subj_difference','polarity_difference']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj_difference\n",
      "polarity_difference\n",
      "avg_word_len_title\n"
     ]
    }
   ],
   "source": [
    "def scaled_checker(df):\n",
    "    for col in df.columns:\n",
    "        if max(df[col]) > 1:\n",
    "            print(col)\n",
    "        if min(df[col]) < 0:\n",
    "            print(col)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "scaled_checker(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subj_difference'] = (df['subj_difference'] - min(df['subj_difference']))/(max(df['subj_difference'])-min(df['subj_difference']))\n",
    "df['polarity_difference'] = (df['polarity_difference'] - min(df['polarity_difference']))/(max(df['polarity_difference'])-min(df['polarity_difference']))\n",
    "df['avg_word_len_title'] = (df['avg_word_len_title'] - min(df['avg_word_len_title']))/(max(df['avg_word_len_title'])-min(df['avg_word_len_title']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_checker(df) # numerical data is scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.to_csv('./text2.csv')\n",
    "df.to_csv('./df2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorin\n",
    "\n",
    "> Note: some of these CountVect instances have a tokenizer, some don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightwing = df[df.yes_right==1]\n",
    "notrightwing = df[df.yes_right==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do subplots here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rightwing.title_polarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rightwing.desc_polarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(notrightwing.title_polarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rightwing.subjectivity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEx1JREFUeJzt3X+sX/V93/HnK/xKt2TFlEtEbWdmnaOFRCpBd4Qp0paGFIwjxVRKJiO1uAjNXQdTu0XVnO4P0mRIdGuKhJbROcKNqdoQlrbDCu6YS4iyTOPHpSEEQxG3wODWFr6tCW2EygZ974/vx+s35vre7/31vVw+z4f01fec9/mc7/l8sLmvez7nfI9TVUiS+vO2te6AJGltGACS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTp2+1h2Yz7nnnltbtmxZ625I0rryyCOP/FlVTSzU7k0dAFu2bGFqamqtuyFJ60qS/z1KO6eAJKlTCwZAkrcneSjJd5IcTvIrrf6lJM8mebS9Lmr1JLk1yXSSx5JcPPRZu5I83V67Vm9YkqSFjDIF9Crwkar6fpIzgG8l+YO27Zeq6qsntb8S2NpeHwRuAz6Y5BzgRmASKOCRJAeq6qWVGIgkaXEWPAOoge+31TPaa75nSO8A7mj7PQCcneR84ArgUFUdbz/0DwHbltd9SdJSjXQNIMlpSR4FjjH4If5g23RTm+a5JclZrbYReGFo95lWO1X95GPtTjKVZGp2dnaRw5EkjWqkAKiq16vqImATcEmS9wOfBv4B8A+Bc4B/05pnro+Yp37ysfZW1WRVTU5MLHgXkyRpiRZ1F1BVfQ/4BrCtqo62aZ5Xgd8ELmnNZoDNQ7ttAo7MU5ckrYFR7gKaSHJ2W/4h4KPAH7d5fZIEuAp4vO1yALim3Q10KfByVR0F7gUuT7IhyQbg8laTJK2BUe4COh/Yn+Q0BoFxV1V9LcnXk0wwmNp5FPjnrf1BYDswDbwCXAtQVceTfA54uLX7bFUdX7mhSJIWI2/mfxR+cnKylvNN4C177lnB3ozuuZs/tibHlSSAJI9U1eRC7fwmsCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqdGeRy0pDn4tFmtd54BSFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUqQUDIMnbkzyU5DtJDif5lVa/IMmDSZ5O8pUkZ7b6WW19um3fMvRZn271p5JcsVqDkiQtbJQzgFeBj1TVjwMXAduSXAr8KnBLVW0FXgKua+2vA16qqr8P3NLakeRCYCfwPmAb8J+SnLaSg5EkjW7BAKiB77fVM9qrgI8AX231/cBVbXlHW6dtvyxJWv3Oqnq1qp4FpoFLVmQUkqRFG+kaQJLTkjwKHAMOAX8CfK+qXmtNZoCNbXkj8AJA2/4y8CPD9Tn2GT7W7iRTSaZmZ2cXPyJJ0khGCoCqer2qLgI2Mfit/b1zNWvvOcW2U9VPPtbeqpqsqsmJiYlRuidJWoJF3QVUVd8DvgFcCpyd5MTD5DYBR9ryDLAZoG3/YeD4cH2OfSRJYzbKXUATSc5uyz8EfBR4Ergf+ERrtgu4uy0faOu07V+vqmr1ne0uoQuArcBDKzUQSdLijPI46POB/e2OnbcBd1XV15I8AdyZ5N8B3wZub+1vB34ryTSD3/x3AlTV4SR3AU8ArwHXV9XrKzscSdKoFgyAqnoM+MAc9WeY4y6eqvor4JOn+KybgJsW301J0krzm8CS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOjXKs4CkN60te+5Z6y5I65YB8BazVj8Qn7v5Y2tyXElL5xSQJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1asEASLI5yf1JnkxyOMkvtPpnkvxpkkfba/vQPp9OMp3kqSRXDNW3tdp0kj2rMyRJ0ihGeRTEa8CnquqPkrwTeCTJobbtlqr6teHGSS4EdgLvA34U+MMk72mbvwD8JDADPJzkQFU9sRIDkSQtzoIBUFVHgaNt+S+TPAlsnGeXHcCdVfUq8GySaeCStm26qp4BSHJna2sASNIaWNQ1gCRbgA8AD7bSDUkeS7IvyYZW2wi8MLTbTKudqi5JWgMjB0CSdwC/C/xiVf0FcBvwY8BFDM4QPn+i6Ry71zz1k4+zO8lUkqnZ2dlRuydJWqSRAiDJGQx++P92Vf0eQFW9WFWvV9VfA1/kb6Z5ZoDNQ7tvAo7MU/8BVbW3qiaranJiYmKx45EkjWiUu4AC3A48WVW/PlQ/f6jZTwGPt+UDwM4kZyW5ANgKPAQ8DGxNckGSMxlcKD6wMsOQJC3WKHcBfQj4GeC7SR5ttV8Grk5yEYNpnOeAnwOoqsNJ7mJwcfc14Pqqeh0gyQ3AvcBpwL6qOryCY9Ea8l/mktafUe4C+hZzz98fnGefm4Cb5qgfnG8/SdL4+E1gSeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4tGABJNie5P8mTSQ4n+YVWPyfJoSRPt/cNrZ4ktyaZTvJYkouHPmtXa/90kl2rNyxJ0kJGOQN4DfhUVb0XuBS4PsmFwB7gvqraCtzX1gGuBLa2127gNhgEBnAj8EHgEuDGE6EhSRq/BQOgqo5W1R+15b8EngQ2AjuA/a3ZfuCqtrwDuKMGHgDOTnI+cAVwqKqOV9VLwCFg24qORpI0skVdA0iyBfgA8CDwrqo6CoOQAM5rzTYCLwztNtNqp6pLktbAyAGQ5B3A7wK/WFV/MV/TOWo1T/3k4+xOMpVkanZ2dtTuSZIWaaQASHIGgx/+v11Vv9fKL7apHdr7sVafATYP7b4JODJP/QdU1d6qmqyqyYmJicWMRZK0CKPcBRTgduDJqvr1oU0HgBN38uwC7h6qX9PuBroUeLlNEd0LXJ5kQ7v4e3mrSZLWwOkjtPkQ8DPAd5M82mq/DNwM3JXkOuB54JNt20FgOzANvAJcC1BVx5N8Dni4tftsVR1fkVFIkhZtwQCoqm8x9/w9wGVztC/g+lN81j5g32I6KElaHX4TWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTCwZAkn1JjiV5fKj2mSR/muTR9to+tO3TSaaTPJXkiqH6tlabTrJn5YciSVqM00do8yXgPwJ3nFS/pap+bbiQ5EJgJ/A+4EeBP0zynrb5C8BPAjPAw0kOVNUTy+j7m9aWPfesdRckaUELBkBVfTPJlhE/bwdwZ1W9CjybZBq4pG2brqpnAJLc2dq+JQNAktaD5VwDuCHJY22KaEOrbQReGGoz02qnqkuS1shSA+A24MeAi4CjwOdbPXO0rXnqb5Bkd5KpJFOzs7NL7J4kaSGjXAN4g6p68cRyki8CX2urM8DmoaabgCNt+VT1kz97L7AXYHJycs6QkHq2lteYnrv5Y2t2bK28JZ0BJDl/aPWngBN3CB0AdiY5K8kFwFbgIeBhYGuSC5KcyeBC8YGld1uStFwLngEk+TLwYeDcJDPAjcCHk1zEYBrnOeDnAKrqcJK7GFzcfQ24vqpeb59zA3AvcBqwr6oOr/hoJEkjG+UuoKvnKN8+T/ubgJvmqB8EDi6qd5KkVeM3gSWpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcWDIAk+5IcS/L4UO2cJIeSPN3eN7R6ktyaZDrJY0kuHtpnV2v/dJJdqzMcSdKoRjkD+BKw7aTaHuC+qtoK3NfWAa4EtrbXbuA2GAQGcCPwQeAS4MYToSFJWhsLBkBVfRM4flJ5B7C/Le8Hrhqq31EDDwBnJzkfuAI4VFXHq+ol4BBvDBVJ0hgt9RrAu6rqKEB7P6/VNwIvDLWbabVT1d8gye4kU0mmZmdnl9g9SdJCVvoicOao1Tz1Nxar9lbVZFVNTkxMrGjnJEl/Y6kB8GKb2qG9H2v1GWDzULtNwJF56pKkNbLUADgAnLiTZxdw91D9mnY30KXAy22K6F7g8iQb2sXfy1tNkrRGTl+oQZIvAx8Gzk0yw+BunpuBu5JcBzwPfLI1PwhsB6aBV4BrAarqeJLPAQ+3dp+tqpMvLEuSxmjBAKiqq0+x6bI52hZw/Sk+Zx+wb1G9kyStmgUDQJJ6tmXPPWty3Odu/tiqH8NHQUhSpwwASeqUASBJnfIagKSRvZXnw3vkGYAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVPLCoAkzyX5bpJHk0y12jlJDiV5ur1vaPUkuTXJdJLHkly8EgOQJC3NSpwB/ERVXVRVk219D3BfVW0F7mvrAFcCW9trN3DbChxbkrREqzEFtAPY35b3A1cN1e+ogQeAs5OcvwrHlySNYLkBUMB/T/JIkt2t9q6qOgrQ3s9r9Y3AC0P7zrSaJGkNLPcfhf9QVR1Jch5wKMkfz9M2c9TqDY0GQbIb4N3vfvcyuydJOpVlnQFU1ZH2fgz4feAS4MUTUzvt/VhrPgNsHtp9E3Bkjs/cW1WTVTU5MTGxnO5Jkuax5ABI8reTvPPEMnA58DhwANjVmu0C7m7LB4Br2t1AlwIvn5gqkiSN33KmgN4F/H6SE5/zO1X135I8DNyV5DrgeeCTrf1BYDswDbwCXLuMY0uSlmnJAVBVzwA/Pkf9z4HL5qgXcP1SjydJWlnLvQgsSatuy5571roLb0k+CkKSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0aewAk2ZbkqSTTSfaM+/iSpIGxBkCS04AvAFcCFwJXJ7lwnH2QJA2M+wzgEmC6qp6pqv8D3AnsGHMfJEmMPwA2Ai8Mrc+0miRpzE4f8/EyR61+oEGyG9jdVr+f5KllHO9c4M+Wsf961NuYexsvOOYu5FeXNea/O0qjcQfADLB5aH0TcGS4QVXtBfauxMGSTFXV5Ep81nrR25h7Gy845l6MY8zjngJ6GNia5IIkZwI7gQNj7oMkiTGfAVTVa0luAO4FTgP2VdXhcfZBkjQw7ikgquogcHBMh1uRqaR1prcx9zZecMy9WPUxp6oWbiVJesvxURCS1Kl1HwALPVoiyVlJvtK2P5hky/h7ubJGGPO/TvJEkseS3JdkpFvC3sxGfYRIkk8kqSTr/o6RUcac5J+2P+vDSX5n3H1caSP83X53kvuTfLv9/d6+Fv1cKUn2JTmW5PFTbE+SW9t/j8eSXLyiHaiqdfticCH5T4C/B5wJfAe48KQ2/wL4jba8E/jKWvd7DGP+CeBvteWf72HMrd07gW8CDwCTa93vMfw5bwW+DWxo6+etdb/HMOa9wM+35QuB59a638sc8z8GLgYeP8X27cAfMPgO1aXAgyt5/PV+BjDKoyV2APvb8leBy5LM9YW09WLBMVfV/VX1Slt9gMH3LdazUR8h8jng3wN/Nc7OrZJRxvzPgC9U1UsAVXVszH1caaOMuYC/05Z/mJO+R7TeVNU3gePzNNkB3FEDDwBnJzl/pY6/3gNglEdL/P82VfUa8DLwI2Pp3epY7OM0rmPwG8R6tuCYk3wA2FxVXxtnx1bRKH/O7wHek+R/Jnkgybax9W51jDLmzwA/nWSGwd2E/3I8XVszq/r4nLHfBrrCFny0xIht1pORx5Pkp4FJ4J+sao9W37xjTvI24BbgZ8fVoTEY5c/5dAbTQB9mcJb3P5K8v6q+t8p9Wy2jjPlq4EtV9fkk/wj4rTbmv1797q2JVf35td7PABZ8tMRwmySnMzhtnO+U681ulDGT5KPAvwU+XlWvjqlvq2WhMb8TeD/wjSTPMZgrPbDOLwSP+nf77qr6v1X1LPAUg0BYr0YZ83XAXQBV9b+AtzN4TtBb1Uj/vy/Veg+AUR4tcQDY1ZY/AXy92tWVdWrBMbfpkP/M4If/ep8XhgXGXFUvV9W5VbWlqrYwuO7x8aqaWpvurohR/m7/VwYX/ElyLoMpoWfG2suVNcqYnwcuA0jyXgYBMDvWXo7XAeCadjfQpcDLVXV0pT58XU8B1SkeLZHks8BUVR0AbmdwmjjN4Df/nWvX4+Ubccz/AXgH8F/a9e7nq+rja9bpZRpxzG8pI475XuDyJE8ArwO/VFV/vna9Xp4Rx/wp4ItJ/hWDqZCfXc+/0CX5MoMpvHPbdY0bgTMAquo3GFzn2A5MA68A167o8dfxfztJ0jKs9ykgSdISGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXq/wHjp4fIW+Xq0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(notrightwing.subjectivity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>desc_polarity</th>\n",
       "      <th>desc_subjectivity</th>\n",
       "      <th>subj_difference</th>\n",
       "      <th>polarity_difference</th>\n",
       "      <th>avg_word_len_title</th>\n",
       "      <th>CC_title</th>\n",
       "      <th>CD_title</th>\n",
       "      <th>DT_title</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD_desc</th>\n",
       "      <th>VBG_desc</th>\n",
       "      <th>VBN_desc</th>\n",
       "      <th>VBP_desc</th>\n",
       "      <th>VBZ_desc</th>\n",
       "      <th>WDT_desc</th>\n",
       "      <th>WP_desc</th>\n",
       "      <th>WP$_desc</th>\n",
       "      <th>WRB_desc</th>\n",
       "      <th>yes_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.201348</td>\n",
       "      <td>0.524758</td>\n",
       "      <td>0.312783</td>\n",
       "      <td>0.444283</td>\n",
       "      <td>0.517420</td>\n",
       "      <td>0.299787</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>0.023112</td>\n",
       "      <td>0.038358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034516</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>0.021060</td>\n",
       "      <td>0.014968</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113371</td>\n",
       "      <td>0.296501</td>\n",
       "      <td>0.107297</td>\n",
       "      <td>0.270642</td>\n",
       "      <td>0.180273</td>\n",
       "      <td>0.070813</td>\n",
       "      <td>0.065313</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.064290</td>\n",
       "      <td>0.070854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039476</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.031546</td>\n",
       "      <td>0.029062</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.012933</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.478975</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       title_polarity  title_subjectivity  desc_polarity  desc_subjectivity  \\\n",
       "count    17148.000000        17148.000000   17148.000000       17148.000000   \n",
       "mean         0.507856            0.201348       0.524758           0.312783   \n",
       "std          0.113371            0.296501       0.107297           0.270642   \n",
       "min          0.000000            0.000000       0.000000           0.000000   \n",
       "25%          0.500000            0.000000       0.500000           0.000000   \n",
       "50%          0.500000            0.000000       0.500000           0.300000   \n",
       "75%          0.500000            0.400000       0.568182           0.500000   \n",
       "max          1.000000            1.000000       1.000000           1.000000   \n",
       "\n",
       "       subj_difference  polarity_difference  avg_word_len_title      CC_title  \\\n",
       "count     17148.000000         17148.000000        17148.000000  17148.000000   \n",
       "mean          0.444283             0.517420            0.299787      0.008506   \n",
       "std           0.180273             0.070813            0.065313      0.032609   \n",
       "min           0.000000             0.000000            0.000000      0.000000   \n",
       "25%           0.325000             0.488722            0.257143      0.000000   \n",
       "50%           0.478975             0.526316            0.294643      0.000000   \n",
       "75%           0.500000             0.539474            0.337662      0.000000   \n",
       "max           1.000000             1.000000            0.714286      0.500000   \n",
       "\n",
       "           CD_title      DT_title    ...          VBD_desc      VBG_desc  \\\n",
       "count  17148.000000  17148.000000    ...      17148.000000  17148.000000   \n",
       "mean       0.023112      0.038358    ...          0.034516      0.024966   \n",
       "std        0.064290      0.070854    ...          0.039476      0.033346   \n",
       "min        0.000000      0.000000    ...          0.000000      0.000000   \n",
       "25%        0.000000      0.000000    ...          0.000000      0.000000   \n",
       "50%        0.000000      0.000000    ...          0.027027      0.000000   \n",
       "75%        0.000000      0.071429    ...          0.058824      0.043478   \n",
       "max        1.000000      0.500000    ...          0.500000      0.333333   \n",
       "\n",
       "           VBN_desc      VBP_desc      VBZ_desc      WDT_desc       WP_desc  \\\n",
       "count  17148.000000  17148.000000  17148.000000  17148.000000  17148.000000   \n",
       "mean       0.021060      0.014968      0.029779      0.002984      0.003853   \n",
       "std        0.031546      0.029062      0.038474      0.010438      0.012933   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.022727      0.000000      0.000000   \n",
       "75%        0.037037      0.024390      0.048780      0.000000      0.000000   \n",
       "max        0.333333      0.400000      0.333333      0.142857      0.200000   \n",
       "\n",
       "           WP$_desc      WRB_desc  yes_right  \n",
       "count  17148.000000  17148.000000    17148.0  \n",
       "mean       0.000145      0.002950        1.0  \n",
       "std        0.002253      0.012852        0.0  \n",
       "min        0.000000      0.000000        1.0  \n",
       "25%        0.000000      0.000000        1.0  \n",
       "50%        0.000000      0.000000        1.0  \n",
       "75%        0.000000      0.000000        1.0  \n",
       "max        0.071429      0.333333        1.0  \n",
       "\n",
       "[8 rows x 79 columns]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightwing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>desc_polarity</th>\n",
       "      <th>desc_subjectivity</th>\n",
       "      <th>subj_difference</th>\n",
       "      <th>polarity_difference</th>\n",
       "      <th>avg_word_len_title</th>\n",
       "      <th>CC_title</th>\n",
       "      <th>CD_title</th>\n",
       "      <th>DT_title</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD_desc</th>\n",
       "      <th>VBG_desc</th>\n",
       "      <th>VBN_desc</th>\n",
       "      <th>VBP_desc</th>\n",
       "      <th>VBZ_desc</th>\n",
       "      <th>WDT_desc</th>\n",
       "      <th>WP_desc</th>\n",
       "      <th>WP$_desc</th>\n",
       "      <th>WRB_desc</th>\n",
       "      <th>yes_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.520245</td>\n",
       "      <td>0.252814</td>\n",
       "      <td>0.535423</td>\n",
       "      <td>0.332736</td>\n",
       "      <td>0.460039</td>\n",
       "      <td>0.518327</td>\n",
       "      <td>0.279079</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>0.029674</td>\n",
       "      <td>0.051855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036158</td>\n",
       "      <td>0.024587</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>0.019808</td>\n",
       "      <td>0.034374</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.124798</td>\n",
       "      <td>0.315929</td>\n",
       "      <td>0.117463</td>\n",
       "      <td>0.284196</td>\n",
       "      <td>0.200754</td>\n",
       "      <td>0.083516</td>\n",
       "      <td>0.062686</td>\n",
       "      <td>0.029995</td>\n",
       "      <td>0.092711</td>\n",
       "      <td>0.069232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045117</td>\n",
       "      <td>0.035878</td>\n",
       "      <td>0.032798</td>\n",
       "      <td>0.037880</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.017275</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.479825</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.316369</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       title_polarity  title_subjectivity  desc_polarity  desc_subjectivity  \\\n",
       "count    19706.000000        19706.000000   19706.000000       19706.000000   \n",
       "mean         0.520245            0.252814       0.535423           0.332736   \n",
       "std          0.124798            0.315929       0.117463           0.284196   \n",
       "min          0.000000            0.000000       0.000000           0.000000   \n",
       "25%          0.500000            0.000000       0.500000           0.000000   \n",
       "50%          0.500000            0.050000       0.500000           0.316369   \n",
       "75%          0.550000            0.487500       0.587500           0.500000   \n",
       "max          1.000000            1.000000       1.000000           1.000000   \n",
       "\n",
       "       subj_difference  polarity_difference  avg_word_len_title      CC_title  \\\n",
       "count     19706.000000         19706.000000        19706.000000  19706.000000   \n",
       "mean          0.460039             0.518327            0.279079      0.010136   \n",
       "std           0.200754             0.083516            0.062686      0.029995   \n",
       "min           0.000000             0.052632            0.057143      0.000000   \n",
       "25%           0.325000             0.479825            0.238095      0.000000   \n",
       "50%           0.479167             0.526316            0.274725      0.000000   \n",
       "75%           0.555556             0.552632            0.317460      0.000000   \n",
       "max           1.000000             0.960526            1.000000      0.250000   \n",
       "\n",
       "           CD_title      DT_title    ...          VBD_desc      VBG_desc  \\\n",
       "count  19706.000000  19706.000000    ...      19706.000000  19706.000000   \n",
       "mean       0.029674      0.051855    ...          0.036158      0.024587   \n",
       "std        0.092711      0.069232    ...          0.045117      0.035878   \n",
       "min        0.000000      0.000000    ...          0.000000      0.000000   \n",
       "25%        0.000000      0.000000    ...          0.000000      0.000000   \n",
       "50%        0.000000      0.000000    ...          0.024390      0.000000   \n",
       "75%        0.000000      0.100000    ...          0.062500      0.045455   \n",
       "max        1.000000      0.500000    ...          0.500000      0.666667   \n",
       "\n",
       "           VBN_desc      VBP_desc      VBZ_desc      WDT_desc       WP_desc  \\\n",
       "count  19706.000000  19706.000000  19706.000000  19706.000000  19706.000000   \n",
       "mean       0.018583      0.019808      0.034374      0.002960      0.004972   \n",
       "std        0.032798      0.037880      0.041952      0.011413      0.017275   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.025000      0.000000      0.000000   \n",
       "75%        0.033333      0.032258      0.058824      0.000000      0.000000   \n",
       "max        0.500000      0.428571      0.333333      0.142857      0.500000   \n",
       "\n",
       "           WP$_desc      WRB_desc  yes_right  \n",
       "count  19706.000000  19706.000000    19706.0  \n",
       "mean       0.000087      0.004557        0.0  \n",
       "std        0.001962      0.016761        0.0  \n",
       "min        0.000000      0.000000        0.0  \n",
       "25%        0.000000      0.000000        0.0  \n",
       "50%        0.000000      0.000000        0.0  \n",
       "75%        0.000000      0.000000        0.0  \n",
       "max        0.100000      0.500000        0.0  \n",
       "\n",
       "[8 rows x 79 columns]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notrightwing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Grams for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_stop_words = ['CNN', 'cnn',\n",
    "                   'national review', 'huffpost','fox','reuters','ap', 'associated press', 'vice','breitbart',\n",
    "                   'nationalreview', 'www', 'content uploads', 'msnbc', 'infowars', 'foxnews','Vice','Breitbart',\n",
    "                  'National Review','Fox News','Reuters','Fast Facts','Infowars','Vice','Content Uploads','MSNBC',\n",
    "                   'www', 'AP','Huffpost','HuffPost','Fox amp Friends','Morning Joe', 'Maddow', 'FOX NEWS'\n",
    "                  ]\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "original_stopwords = list(ENGLISH_STOP_WORDS)\n",
    "cust_stop_words += original_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = text['yes_right'] == 1\n",
    "notright = text['yes_right'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_title = text[right].title\n",
    "right_desc = text[right].description\n",
    "notright_title = text[notright].title\n",
    "notright_desc = text[notright].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "cvec = CountVectorizer(preprocessor=lemmatizer.lemmatize, tokenizer=tokenizer.tokenize, \n",
    "                       ngram_range=(1,1), stop_words=cust_stop_words, min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec.fit(right_title)\n",
    "rt_counts = pd.DataFrame(cvec.transform(right_title).todense(),\n",
    "                       columns=cvec.get_feature_names())\n",
    "title_counts = rt_counts.sum(axis=0)\n",
    "title_counts = pd.DataFrame(title_counts.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(1,1), stop_words=cust_stop_words, min_df=10)\n",
    "cvec.fit(notright_title)\n",
    "nrt_counts = pd.DataFrame(cvec.transform(notright_title).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrt_counts = nrt_counts.sum(axis=0)\n",
    "title_counts['not right'] = nrt_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>2979</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>2862</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>1101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is</th>\n",
       "      <td>643</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>568</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>521</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea</th>\n",
       "      <td>502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kim</th>\n",
       "      <td>397</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House</th>\n",
       "      <td>397</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>379</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>375</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>358</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>342</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not</th>\n",
       "      <td>341</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Report</th>\n",
       "      <td>340</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>President</th>\n",
       "      <td>329</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New</th>\n",
       "      <td>324</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>After</th>\n",
       "      <td>324</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Border</th>\n",
       "      <td>322</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>322</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           right  not right\n",
       "Trump       2979        NaN\n",
       "s           2862        NaN\n",
       "The         1101        NaN\n",
       "Is           643        NaN\n",
       "t            568        NaN\n",
       "North        521        NaN\n",
       "Korea        502        NaN\n",
       "Kim          397        NaN\n",
       "House        397        NaN\n",
       "U            379        NaN\n",
       "A            375        NaN\n",
       "S            358        NaN\n",
       "Day          342        NaN\n",
       "Not          341        NaN\n",
       "Report       340        NaN\n",
       "President    329        NaN\n",
       "New          324        NaN\n",
       "After        324        NaN\n",
       "Border       322        NaN\n",
       "US           322        NaN"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>129</td>\n",
       "      <td>1074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>307</td>\n",
       "      <td>492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>220</td>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>21</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>16</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>21</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>81</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>15</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>31</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>73</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report</th>\n",
       "      <td>216</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit</th>\n",
       "      <td>244</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>21</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>34</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>57</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>12</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>85</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>105</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>32</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>121</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           right  not right\n",
       "new          129     1074.0\n",
       "says         307      492.0\n",
       "2018         220      430.0\n",
       "house         21      425.0\n",
       "white         16      348.0\n",
       "world         21      340.0\n",
       "18            81      339.0\n",
       "just          15      326.0\n",
       "like          31      320.0\n",
       "video         73      299.0\n",
       "report       216      293.0\n",
       "summit       244      283.0\n",
       "women         21      278.0\n",
       "people        34      278.0\n",
       "president     57      273.0\n",
       "watch         12      263.0\n",
       "year          85      253.0\n",
       "man          105      252.0\n",
       "day           32      250.0\n",
       "say          121      240.0"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts.sort_values('not right', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Grams for Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=lemmatizer.lemmatize, tokenizer=tokenizer.tokenize,\n",
    "                       ngram_range=(1,1), stop_words='english', min_df=10)\n",
    "cvec.fit(right_desc)\n",
    "rd_counts = pd.DataFrame(cvec.transform(right_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "desc_counts = rd_counts.sum(axis=0)\n",
    "desc_counts = pd.DataFrame(desc_counts.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(1,1), stop_words='english', min_df=10)\n",
    "cvec.fit(notright_desc)\n",
    "nrd_counts = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrd_counts = nrd_counts.sum(axis=0)\n",
    "desc_counts['not right'] = nrd_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>3830</td>\n",
       "      <td>4756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>3215</td>\n",
       "      <td>2796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>3121</td>\n",
       "      <td>857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>2794</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>1480</td>\n",
       "      <td>2052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>1214</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>1205</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald</th>\n",
       "      <td>1111</td>\n",
       "      <td>1374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north</th>\n",
       "      <td>938</td>\n",
       "      <td>721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>909</td>\n",
       "      <td>527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>843</td>\n",
       "      <td>838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>739</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>734</td>\n",
       "      <td>768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police</th>\n",
       "      <td>701</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuesday</th>\n",
       "      <td>682</td>\n",
       "      <td>416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>632</td>\n",
       "      <td>830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border</th>\n",
       "      <td>626</td>\n",
       "      <td>451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim</th>\n",
       "      <td>621</td>\n",
       "      <td>528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>614</td>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>612</td>\n",
       "      <td>417.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           right  not right\n",
       "trump       3830     4756.0\n",
       "president   3215     2796.0\n",
       "news        3121      857.0\n",
       "fox         2794      180.0\n",
       "new         1480     2052.0\n",
       "house       1214     1033.0\n",
       "said        1205     1093.0\n",
       "donald      1111     1374.0\n",
       "north        938      721.0\n",
       "state        909      527.0\n",
       "says         843      838.0\n",
       "year         739      584.0\n",
       "white        734      768.0\n",
       "police       701      265.0\n",
       "tuesday      682      416.0\n",
       "people       632      830.0\n",
       "border       626      451.0\n",
       "kim          621      528.0\n",
       "week         614      458.0\n",
       "national     612      417.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>3830</td>\n",
       "      <td>4756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>3215</td>\n",
       "      <td>2796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>1480</td>\n",
       "      <td>2052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald</th>\n",
       "      <td>1111</td>\n",
       "      <td>1374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>1205</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>1214</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>192</td>\n",
       "      <td>958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>3121</td>\n",
       "      <td>857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>843</td>\n",
       "      <td>838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>632</td>\n",
       "      <td>830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discuss</th>\n",
       "      <td>275</td>\n",
       "      <td>777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>734</td>\n",
       "      <td>768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north</th>\n",
       "      <td>938</td>\n",
       "      <td>721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michael</th>\n",
       "      <td>242</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>424</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>739</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney</th>\n",
       "      <td>316</td>\n",
       "      <td>569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohen</th>\n",
       "      <td>69</td>\n",
       "      <td>562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>administration</th>\n",
       "      <td>409</td>\n",
       "      <td>562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>407</td>\n",
       "      <td>561.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                right  not right\n",
       "trump            3830     4756.0\n",
       "president        3215     2796.0\n",
       "new              1480     2052.0\n",
       "donald           1111     1374.0\n",
       "said             1205     1093.0\n",
       "house            1214     1033.0\n",
       "cnn               192      958.0\n",
       "news             3121      857.0\n",
       "says              843      838.0\n",
       "people            632      830.0\n",
       "discuss           275      777.0\n",
       "white             734      768.0\n",
       "north             938      721.0\n",
       "michael           242      718.0\n",
       "day               424      623.0\n",
       "year              739      584.0\n",
       "attorney          316      569.0\n",
       "cohen              69      562.0\n",
       "administration    409      562.0\n",
       "time              407      561.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts.sort_values('not right', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGrams for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(2,2), stop_words='english', min_df=10)\n",
    "cvec.fit(right_title)\n",
    "rt_counts2 = pd.DataFrame(cvec.transform(right_title).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "title_counts2 = rt_counts2.sum(axis=0)\n",
    "title_counts2 = pd.DataFrame(title_counts2.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(2,2), stop_words='english', min_df=10)\n",
    "cvec.fit(notright_title)\n",
    "nrt_counts2 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrt_counts2 = nrt_counts2.sum(axis=0)\n",
    "title_counts2['not right'] = nrt_counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fox new</th>\n",
       "      <td>961</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea</th>\n",
       "      <td>417</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>303</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim jong</th>\n",
       "      <td>182</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>181</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>181</td>\n",
       "      <td>904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ig report</th>\n",
       "      <td>141</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supreme court</th>\n",
       "      <td>129</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim</th>\n",
       "      <td>121</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judicial activism</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day liberal</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>100</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>91</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox news</th>\n",
       "      <td>85</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   right  not right\n",
       "fox new              961        NaN\n",
       "north korea          417      386.0\n",
       "donald trump         303     1352.0\n",
       "kim jong             182      414.0\n",
       "white house          181      634.0\n",
       "president trump      181      904.0\n",
       "ig report            141        7.0\n",
       "supreme court        129       94.0\n",
       "trump kim            121       61.0\n",
       "judicial activism    104        NaN\n",
       "liberal judicial     104        NaN\n",
       "day liberal          104        NaN\n",
       "new york             100      420.0\n",
       "year old              91      201.0\n",
       "fox news              85      101.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>303</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>181</td>\n",
       "      <td>904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>181</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>100</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim jong</th>\n",
       "      <td>182</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michael cohen</th>\n",
       "      <td>25</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump administration</th>\n",
       "      <td>67</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea</th>\n",
       "      <td>417</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean</th>\n",
       "      <td>54</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel</th>\n",
       "      <td>28</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert mueller</th>\n",
       "      <td>16</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rudy giuliani</th>\n",
       "      <td>13</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united states</th>\n",
       "      <td>18</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormy daniels</th>\n",
       "      <td>45</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>91</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      right  not right\n",
       "donald trump            303     1352.0\n",
       "president trump         181      904.0\n",
       "white house             181      634.0\n",
       "new york                100      420.0\n",
       "kim jong                182      414.0\n",
       "michael cohen            25      405.0\n",
       "trump administration     67      400.0\n",
       "north korea             417      386.0\n",
       "north korean             54      254.0\n",
       "special counsel          28      236.0\n",
       "robert mueller           16      232.0\n",
       "rudy giuliani            13      224.0\n",
       "united states            18      223.0\n",
       "stormy daniels           45      213.0\n",
       "year old                 91      201.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts2.sort_values('not right', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGrams for Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(2,2), stop_words='english', min_df=10)\n",
    "cvec.fit(right_desc)\n",
    "rd_counts2 = pd.DataFrame(cvec.transform(right_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "desc_counts2 = rd_counts2.sum(axis=0)\n",
    "desc_counts2 = pd.DataFrame(desc_counts2.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(2,2), stop_words='english', min_df=10)\n",
    "cvec.fit(notright_desc)\n",
    "nrd_counts2 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrd_counts2 = nrd_counts2.sum(axis=0)\n",
    "desc_counts2['not right'] = nrd_counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fox news</th>\n",
       "      <td>2463</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>1187</td>\n",
       "      <td>904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>1088</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president donald</th>\n",
       "      <td>932</td>\n",
       "      <td>673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>621</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>481</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim jong</th>\n",
       "      <td>474</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea</th>\n",
       "      <td>473</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>339</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united states</th>\n",
       "      <td>314</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean</th>\n",
       "      <td>313</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump administration</th>\n",
       "      <td>257</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breitbart news</th>\n",
       "      <td>252</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nationalreview com</th>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com wp</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      right  not right\n",
       "fox news               2463      101.0\n",
       "president trump        1187      904.0\n",
       "donald trump           1088     1352.0\n",
       "president donald        932      673.0\n",
       "white house             621      634.0\n",
       "new york                481      420.0\n",
       "kim jong                474      414.0\n",
       "north korea             473      386.0\n",
       "year old                339      201.0\n",
       "united states           314      223.0\n",
       "north korean            313      254.0\n",
       "trump administration    257      400.0\n",
       "breitbart news          252        NaN\n",
       "nationalreview com      240        NaN\n",
       "com wp                  238        NaN"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>1088</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>1187</td>\n",
       "      <td>904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president donald</th>\n",
       "      <td>932</td>\n",
       "      <td>673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>621</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>481</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim jong</th>\n",
       "      <td>474</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michael cohen</th>\n",
       "      <td>45</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump administration</th>\n",
       "      <td>257</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea</th>\n",
       "      <td>473</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean</th>\n",
       "      <td>313</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel</th>\n",
       "      <td>169</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert mueller</th>\n",
       "      <td>136</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rudy giuliani</th>\n",
       "      <td>65</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united states</th>\n",
       "      <td>314</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormy daniels</th>\n",
       "      <td>50</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      right  not right\n",
       "donald trump           1088     1352.0\n",
       "president trump        1187      904.0\n",
       "president donald        932      673.0\n",
       "white house             621      634.0\n",
       "new york                481      420.0\n",
       "kim jong                474      414.0\n",
       "michael cohen            45      405.0\n",
       "trump administration    257      400.0\n",
       "north korea             473      386.0\n",
       "north korean            313      254.0\n",
       "special counsel         169      236.0\n",
       "robert mueller          136      232.0\n",
       "rudy giuliani            65      224.0\n",
       "united states           314      223.0\n",
       "stormy daniels           50      213.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts2.sort_values('not right',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriGrams for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(3,3), stop_words='english', min_df=5)\n",
    "cvec.fit(right_title)\n",
    "rt_counts3 = pd.DataFrame(cvec.transform(right_title).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "title_counts3 = rt_counts3.sum(axis=0)\n",
    "title_counts3 = pd.DataFrame(title_counts3.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(3,3), stop_words='english', min_df=5)\n",
    "cvec.fit(notright_title)\n",
    "nrt_counts3 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrt_counts3 = nrt_counts3.sum(axis=0)\n",
    "title_counts3['not right'] = nrt_counts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day liberal judicial</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea summit</th>\n",
       "      <td>76</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim summit</th>\n",
       "      <td>66</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say fox new</th>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says fox new</th>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police say fox</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report fox new</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox news rundown</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south china sea</th>\n",
       "      <td>26</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border patrol agents</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york times</th>\n",
       "      <td>23</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim jong</th>\n",
       "      <td>23</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judicial activism june</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cartoons day march</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           right  not right\n",
       "liberal judicial activism    104        NaN\n",
       "day liberal judicial         104        NaN\n",
       "north korea summit            76       38.0\n",
       "trump kim summit              66        8.0\n",
       "say fox new                   53        NaN\n",
       "says fox new                  37        NaN\n",
       "police say fox                34        NaN\n",
       "report fox new                29        NaN\n",
       "fox news rundown              27        NaN\n",
       "south china sea               26       13.0\n",
       "border patrol agents          24        NaN\n",
       "new york times                23      155.0\n",
       "trump kim jong                23       41.0\n",
       "judicial activism june        22        NaN\n",
       "cartoons day march            21        NaN"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts3.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new york times</th>\n",
       "      <td>23</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york city</th>\n",
       "      <td>7</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump legal team</th>\n",
       "      <td>5</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit north korea</th>\n",
       "      <td>5</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim jong</th>\n",
       "      <td>23</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump white house</th>\n",
       "      <td>8</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe high school</th>\n",
       "      <td>7</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santa fe high</th>\n",
       "      <td>9</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea summit</th>\n",
       "      <td>76</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald trump jr</th>\n",
       "      <td>14</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit kim jong</th>\n",
       "      <td>15</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meeting kim jong</th>\n",
       "      <td>14</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormy daniels lawyer</th>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero tolerance immigration</th>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>york attorney general</th>\n",
       "      <td>6</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            right  not right\n",
       "new york times                 23      155.0\n",
       "new york city                   7       60.0\n",
       "trump legal team                5       48.0\n",
       "summit north korea              5       42.0\n",
       "trump kim jong                 23       41.0\n",
       "trump white house               8       41.0\n",
       "fe high school                  7       39.0\n",
       "santa fe high                   9       38.0\n",
       "north korea summit             76       38.0\n",
       "donald trump jr                14       34.0\n",
       "summit kim jong                15       27.0\n",
       "meeting kim jong               14       26.0\n",
       "stormy daniels lawyer           7       26.0\n",
       "zero tolerance immigration      6       23.0\n",
       "york attorney general           6       18.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts3.sort_values('not right', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriGrams for Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(3,3), stop_words='english', min_df=5)\n",
    "cvec.fit(right_desc)\n",
    "rd_counts3 = pd.DataFrame(cvec.transform(right_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "desc_counts3 = rd_counts3.sum(axis=0)\n",
    "desc_counts3 = pd.DataFrame(desc_counts3.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(3,3), stop_words='english', min_df=5)\n",
    "cvec.fit(notright_desc)\n",
    "nrd_counts3 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrd_counts3 = nrd_counts3.sum(axis=0)\n",
    "desc_counts3['not right'] = nrd_counts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>president donald trump</th>\n",
       "      <td>926</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nationalreview com wp</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com www nationalreview</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp com www</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com wp content</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp content uploads</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www nationalreview com</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content uploads 2018</th>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jpg fit 1024</th>\n",
       "      <td>218</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024 2c597 ssl</th>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit 1024 2c597</th>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox amp friends</th>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox news channel</th>\n",
       "      <td>142</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictator kim jong</th>\n",
       "      <td>125</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york times</th>\n",
       "      <td>118</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        right  not right\n",
       "president donald trump    926      672.0\n",
       "nationalreview com wp     238        NaN\n",
       "com www nationalreview    238        NaN\n",
       "wp com www                238        NaN\n",
       "com wp content            238        NaN\n",
       "wp content uploads        238        NaN\n",
       "www nationalreview com    238        NaN\n",
       "content uploads 2018      233        NaN\n",
       "jpg fit 1024              218        NaN\n",
       "1024 2c597 ssl            216        NaN\n",
       "fit 1024 2c597            216        NaN\n",
       "fox amp friends           162        NaN\n",
       "fox news channel          142        NaN\n",
       "dictator kim jong         125       21.0\n",
       "new york times            118      155.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts3.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>president donald trump</th>\n",
       "      <td>926</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean leader</th>\n",
       "      <td>102</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york times</th>\n",
       "      <td>118</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leader kim jong</th>\n",
       "      <td>108</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean leader kim</th>\n",
       "      <td>91</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel robert</th>\n",
       "      <td>110</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counsel robert mueller</th>\n",
       "      <td>108</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbi director james</th>\n",
       "      <td>60</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director james comey</th>\n",
       "      <td>59</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lawyer michael cohen</th>\n",
       "      <td>15</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney general jeff</th>\n",
       "      <td>48</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general jeff sessions</th>\n",
       "      <td>48</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york city</th>\n",
       "      <td>102</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney michael cohen</th>\n",
       "      <td>9</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero tolerance policy</th>\n",
       "      <td>15</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        right  not right\n",
       "president donald trump    926      672.0\n",
       "north korean leader       102      158.0\n",
       "new york times            118      155.0\n",
       "leader kim jong           108      149.0\n",
       "korean leader kim          91      133.0\n",
       "special counsel robert    110      125.0\n",
       "counsel robert mueller    108      122.0\n",
       "fbi director james         60       81.0\n",
       "director james comey       59       81.0\n",
       "lawyer michael cohen       15       69.0\n",
       "attorney general jeff      48       64.0\n",
       "general jeff sessions      48       64.0\n",
       "new york city             102       60.0\n",
       "attorney michael cohen      9       59.0\n",
       "zero tolerance policy      15       57.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts3.sort_values('not right',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuadGrams for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(4,4), stop_words='english', min_df=3)\n",
    "cvec.fit(right_title)\n",
    "rt_counts4 = pd.DataFrame(cvec.transform(right_title).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "title_counts4 = rt_counts4.sum(axis=0)\n",
    "title_counts4 = pd.DataFrame(title_counts4.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(4,4), stop_words='english', min_df=3)\n",
    "cvec.fit(notright_title)\n",
    "nrt_counts4 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrt_counts4 = nrt_counts4.sum(axis=0)\n",
    "title_counts4['not right'] = nrt_counts4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day liberal judicial activism</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police say fox new</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism june</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism march</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism february</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism april</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report says fox new</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>things caught eye today</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national review summer internship</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion notes melania trump</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea kim jong</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector union dues cas</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ms 13 gang members</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santa fe high school</th>\n",
       "      <td>7</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public sector union dues</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    right  not right\n",
       "day liberal judicial activism         104        NaN\n",
       "police say fox new                     34        NaN\n",
       "liberal judicial activism june         22        NaN\n",
       "liberal judicial activism march        20        NaN\n",
       "liberal judicial activism february     19        NaN\n",
       "liberal judicial activism april        19        NaN\n",
       "report says fox new                    13        NaN\n",
       "things caught eye today                11        NaN\n",
       "national review summer internship       9        NaN\n",
       "fashion notes melania trump             9        NaN\n",
       "north korea kim jong                    9        NaN\n",
       "sector union dues cas                   7        NaN\n",
       "ms 13 gang members                      7        NaN\n",
       "santa fe high school                    7       38.0\n",
       "public sector union dues                7        NaN"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts4.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>santa fe high school</th>\n",
       "      <td>7</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york attorney general</th>\n",
       "      <td>6</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house correspondents dinner</th>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney general eric schneiderman</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit north korea kim</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump meeting kim jong</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dhs secretary kirstjen nielsen</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elon musk boring company</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>designer kate spade dead</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waffle house shooting suspect</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero tolerance immigration polici</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump north korea summit</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santa fe school shooting</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtv movie tv award</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day liberal judicial activism</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    right  not right\n",
       "santa fe high school                    7       38.0\n",
       "new york attorney general               6       18.0\n",
       "white house correspondents dinner       5       12.0\n",
       "attorney general eric schneiderman      3        7.0\n",
       "summit north korea kim                  3        7.0\n",
       "trump meeting kim jong                  6        3.0\n",
       "dhs secretary kirstjen nielsen          3        3.0\n",
       "elon musk boring company                4        1.0\n",
       "designer kate spade dead                4        1.0\n",
       "waffle house shooting suspect           3        1.0\n",
       "zero tolerance immigration polici       4        0.0\n",
       "trump north korea summit                4        0.0\n",
       "santa fe school shooting                3        0.0\n",
       "mtv movie tv award                      3        0.0\n",
       "day liberal judicial activism         104        NaN"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts4.sort_values('not right', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuadGrams for Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(4,4), stop_words=cust_stop_words, min_df=5)\n",
    "cvec.fit(right_desc)\n",
    "rd_counts4 = pd.DataFrame(cvec.transform(right_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "desc_counts4 = rd_counts4.sum(axis=0)\n",
    "desc_counts4 = pd.DataFrame(desc_counts4.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(4,4), stop_words=cust_stop_words, min_df=5)\n",
    "cvec.fit(notright_desc)\n",
    "nrd_counts4 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrd_counts4 = nrd_counts4.sum(axis=0)\n",
    "desc_counts4['not right'] = nrd_counts4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>com wp content uploads</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp com com wp</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com com wp content</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp content uploads 2018</th>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit 1024 2c597 ssl</th>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jpg fit 1024 2c597</th>\n",
       "      <td>209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictator kim jong un</th>\n",
       "      <td>125</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leader kim jong un</th>\n",
       "      <td>108</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel robert mueller</th>\n",
       "      <td>108</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean dictator kim</th>\n",
       "      <td>94</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean dictator kim jong</th>\n",
       "      <td>94</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean leader kim</th>\n",
       "      <td>91</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean leader kim jong</th>\n",
       "      <td>90</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https i0 wp com</th>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i0 wp com com</th>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                right  not right\n",
       "com wp content uploads            238        NaN\n",
       "wp com com wp                     238        NaN\n",
       "com com wp content                238        NaN\n",
       "wp content uploads 2018           233        NaN\n",
       "fit 1024 2c597 ssl                216        NaN\n",
       "jpg fit 1024 2c597                209        NaN\n",
       "dictator kim jong un              125       21.0\n",
       "leader kim jong un                108      148.0\n",
       "special counsel robert mueller    108      122.0\n",
       "north korean dictator kim          94       17.0\n",
       "korean dictator kim jong           94       16.0\n",
       "north korean leader kim            91      133.0\n",
       "korean leader kim jong             90      132.0\n",
       "https i0 wp com                    83        NaN\n",
       "i0 wp com com                      83        NaN"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts4.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leader kim jong un</th>\n",
       "      <td>108</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean leader kim</th>\n",
       "      <td>91</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean leader kim jong</th>\n",
       "      <td>90</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel robert mueller</th>\n",
       "      <td>108</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbi director james comey</th>\n",
       "      <td>59</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney general jeff sessions</th>\n",
       "      <td>48</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>former fbi director james</th>\n",
       "      <td>46</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house press secretary</th>\n",
       "      <td>69</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secretary state mike pompeo</th>\n",
       "      <td>53</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump north korean leader</th>\n",
       "      <td>26</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim jong un</th>\n",
       "      <td>43</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santa fe high school</th>\n",
       "      <td>20</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us president donald trump</th>\n",
       "      <td>7</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house press secretary sarah</th>\n",
       "      <td>43</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first lady melania trump</th>\n",
       "      <td>60</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                right  not right\n",
       "leader kim jong un                108      148.0\n",
       "north korean leader kim            91      133.0\n",
       "korean leader kim jong             90      132.0\n",
       "special counsel robert mueller    108      122.0\n",
       "fbi director james comey           59       81.0\n",
       "attorney general jeff sessions     48       63.0\n",
       "former fbi director james          46       62.0\n",
       "white house press secretary        69       47.0\n",
       "secretary state mike pompeo        53       47.0\n",
       "trump north korean leader          26       45.0\n",
       "trump kim jong un                  43       41.0\n",
       "santa fe high school               20       38.0\n",
       "us president donald trump           7       36.0\n",
       "house press secretary sarah        43       35.0\n",
       "first lady melania trump           60       35.0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts4.sort_values('not right', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv('./text2.csv').drop('Unnamed: 0', axis=1)\n",
    "df = pd.read_csv('./df2.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_stop_words = ['CNN', 'cnn', 'NR',\n",
    "                   'national review', 'huffpost','fox','reuters','ap', 'associated press', 'vice','breitbart',\n",
    "                   'nationalreview', 'www', 'content uploads', 'msnbc', 'infowars', 'foxnews','Vice','Breitbart',\n",
    "                  'National Review','Fox News','Reuters','Fast Facts','Infowars','Vice','Content Uploads','MSNBC',\n",
    "                   'www', 'AP','Huffpost','HuffPost','Fox amp Friends','Morning Joe', 'Maddow', 'FOX NEWS'\n",
    "                  ]\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "original_stopwords = list(ENGLISH_STOP_WORDS)\n",
    "cust_stop_words += original_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For text data only\n",
    "X = text['combined']\n",
    "y = text['yes_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=lemmatizer.lemmatize,\n",
    "#                        tokenizer=tokenizer.tokenize,\n",
    "                       strip_accents='ascii',\n",
    "                       ngram_range=(2,4),\n",
    "                       stop_words=cust_stop_words,\n",
    "                       min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(2, 4),\n",
       "        preprocessor=<bound method WordNetLemmatizer.lemmatize of <WordNetLemmatizer>>,\n",
       "        stop_words=['CNN', 'cnn', 'NR', 'national review', 'huffpost', 'fox', 'reuters', 'ap', 'associated press', 'vice', 'breitbart', 'nationalreview', 'www', 'content uploads', 'msnbc', 'infowars', 'foxnews', 'Vice', 'Breitbart', 'National Review', 'Fox News', 'Reuters', 'Fast Facts', 'Infowars', 'Vice',...', 'between', 'toward', 'who', 'her', 'noone', 'beyond', 'eg', 'yours', 'front', 'myself', 'beside'],\n",
       "        strip_accents='ascii', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feats = pd.DataFrame(cvec.transform(X_train).todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Donald Trump              2199\n",
       "President Trump           1795\n",
       "White House               1292\n",
       "North Korea               1220\n",
       "President Donald          1220\n",
       "President Donald Trump    1216\n",
       "Kim Jong                   946\n",
       "New York                   803\n",
       "Jong Un                    758\n",
       "Kim Jong Un                756\n",
       "Trump administration       524\n",
       "Michael Cohen              512\n",
       "North Korean               493\n",
       "year old                   479\n",
       "United States              434\n",
       "Supreme Court              403\n",
       "Stormy Daniels             324\n",
       "Robert Mueller             316\n",
       "World Cup                  275\n",
       "Rudy Giuliani              262\n",
       "dtype: int64"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = X_feats.sum(axis=0)\n",
    "word_counts.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train = cvec.transform(X_train).todense()\n",
    "cv_test = cvec.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(cv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85502894356005787"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(cv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73485999565878013"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(cv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.83      0.77      4927\n",
      "          1       0.76      0.62      0.69      4287\n",
      "\n",
      "avg / total       0.74      0.73      0.73      9214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr.predict(cv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4108  819]\n",
      " [1624 2663]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, lr.predict(cv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76828938361734167"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, cv_test, y_test, cv=7, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = lr.coef_[0]\n",
    "fts = cvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>abs</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8273</th>\n",
       "      <td>We speak</td>\n",
       "      <td>2.772455</td>\n",
       "      <td>-2.772455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>Raw video</td>\n",
       "      <td>2.614837</td>\n",
       "      <td>2.614837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Ali Velshi</td>\n",
       "      <td>2.586766</td>\n",
       "      <td>-2.586766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8610</th>\n",
       "      <td>Your World</td>\n",
       "      <td>2.576522</td>\n",
       "      <td>2.576522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>TEL AVIV</td>\n",
       "      <td>2.547240</td>\n",
       "      <td>2.547240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12552</th>\n",
       "      <td>talks Rachel</td>\n",
       "      <td>2.407425</td>\n",
       "      <td>-2.407425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8153</th>\n",
       "      <td>Visit post</td>\n",
       "      <td>2.397209</td>\n",
       "      <td>2.397209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>Stephanie Ruhle</td>\n",
       "      <td>2.392614</td>\n",
       "      <td>-2.392614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>News News</td>\n",
       "      <td>2.308490</td>\n",
       "      <td>2.308490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>Rachel reports</td>\n",
       "      <td>2.206523</td>\n",
       "      <td>-2.206523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7272</th>\n",
       "      <td>Today Comic</td>\n",
       "      <td>2.139608</td>\n",
       "      <td>-2.139608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>far left</td>\n",
       "      <td>2.125390</td>\n",
       "      <td>2.125390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Ari Melber</td>\n",
       "      <td>2.028391</td>\n",
       "      <td>-2.028391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>Fake News</td>\n",
       "      <td>2.004373</td>\n",
       "      <td>2.004373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>At The</td>\n",
       "      <td>1.968795</td>\n",
       "      <td>-1.968795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>Meet Midterms</td>\n",
       "      <td>1.964083</td>\n",
       "      <td>-1.964083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>Masters Universe</td>\n",
       "      <td>1.959815</td>\n",
       "      <td>1.959815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>Friday Links</td>\n",
       "      <td>1.915654</td>\n",
       "      <td>1.915654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Charles Krauthammer</td>\n",
       "      <td>1.903034</td>\n",
       "      <td>1.903034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11616</th>\n",
       "      <td>provides insight</td>\n",
       "      <td>1.875589</td>\n",
       "      <td>1.875589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>Headlines June</td>\n",
       "      <td>1.870587</td>\n",
       "      <td>-1.870587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>Of The</td>\n",
       "      <td>1.858872</td>\n",
       "      <td>-1.858872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10640</th>\n",
       "      <td>left wing</td>\n",
       "      <td>1.857197</td>\n",
       "      <td>1.857197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11196</th>\n",
       "      <td>official says</td>\n",
       "      <td>1.842161</td>\n",
       "      <td>1.842161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>Video com</td>\n",
       "      <td>1.837995</td>\n",
       "      <td>-1.837995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feat       abs      coef\n",
       "8273              We speak  2.772455 -2.772455\n",
       "5504             Raw video  2.614837  2.614837\n",
       "485             Ali Velshi  2.586766 -2.586766\n",
       "8610            Your World  2.576522  2.576522\n",
       "6597              TEL AVIV  2.547240  2.547240\n",
       "12552         talks Rachel  2.407425 -2.407425\n",
       "8153            Visit post  2.397209  2.397209\n",
       "6444       Stephanie Ruhle  2.392614 -2.392614\n",
       "4740             News News  2.308490  2.308490\n",
       "5487        Rachel reports  2.206523 -2.206523\n",
       "7272           Today Comic  2.139608 -2.139608\n",
       "9864              far left  2.125390  2.125390\n",
       "700             Ari Melber  2.028391 -2.028391\n",
       "2228             Fake News  2.004373  2.004373\n",
       "748                 At The  1.968795 -1.968795\n",
       "4226         Meet Midterms  1.964083 -1.964083\n",
       "4143      Masters Universe  1.959815  1.959815\n",
       "2478          Friday Links  1.915654  1.915654\n",
       "1211   Charles Krauthammer  1.903034  1.903034\n",
       "11616     provides insight  1.875589  1.875589\n",
       "2839        Headlines June  1.870587 -1.870587\n",
       "4922                Of The  1.858872 -1.858872\n",
       "10640            left wing  1.857197  1.857197\n",
       "11196        official says  1.842161  1.842161\n",
       "8138             Video com  1.837995 -1.837995"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    list(zip(fts, np.abs(cfs), cfs)),\n",
    "    columns=['feat','abs','coef']).sort_values('abs',ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passive Aggressive Classifier** on Same CountVectorized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(C=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84153400868306805"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.fit(cv_train, y_train)\n",
    "pac.score(cv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71847189060125893"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.score(cv_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(\n",
    "    strip_accents='ascii',\n",
    "    preprocessor=lemmatizer.lemmatize,\n",
    "    ngram_range=(2,4),\n",
    "    stop_words=cust_stop_words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 4), norm='l2',\n",
       "        preprocessor=<bound method WordNetLemmatizer.lemmatize of <WordNetLemmatizer>>,\n",
       "        smooth_idf=True,\n",
       "        stop_words=['CNN', 'cnn', 'NR', 'national review', 'huffpost', 'fox', 'reuters', 'ap', 'associated press', 'vice', 'breitbart', 'nationalreview', 'www', 'content uploads', 'msnbc', 'infowars', 'foxnews', 'Vice', 'Breitbart', 'National Review', 'Fox News', 'Reuters', 'Fast Facts', 'Infowars', 'Vice',...', 'between', 'toward', 'who', 'her', 'noone', 'beyond', 'eg', 'yours', 'front', 'myself', 'beside'],\n",
       "        strip_accents='ascii', sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train = tf.transform(X_train)\n",
    "tf_test = tf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l2','l1'],\n",
    "    'C': [1.0,0.6]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(lr, parameters, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l2', 'l1'], 'C': [1.0, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99692474674384945"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73876709355328851"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(tf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.87      0.78      4927\n",
      "          1       0.80      0.59      0.68      4287\n",
      "\n",
      "avg / total       0.75      0.74      0.73      9214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid.predict(tf_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4284  643]\n",
      " [1764 2523]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, grid.predict(tf_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gettin passive aggressive with it now*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac = PassiveAggressiveClassifier(random_state=42)\n",
    "pac.fit(tf_train, y_train)\n",
    "pac.score(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77903190796613853"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.score(tf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at Numerical Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[col for col in df.columns if col != 'yes_right']]\n",
    "y = df['yes_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74232995658465994, 0.60169307575428699)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_train, y_train), knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6296671490593343, 0.6296671490593343)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_train, y_train), lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('model', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "#     ('poly', PolynomialFeatures(interaction_only=True)),\n",
    "#     ('pca', PCA()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6296671490593343, 0.63338398089863257)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train), pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>coef_abs</th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-3.542671</td>\n",
       "      <td>3.542671</td>\n",
       "      <td>PRP$_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3.161655</td>\n",
       "      <td>3.161655</td>\n",
       "      <td>NNPS_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-3.045602</td>\n",
       "      <td>3.045602</td>\n",
       "      <td>CC_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.939313</td>\n",
       "      <td>2.939313</td>\n",
       "      <td>avg_word_len_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2.722251</td>\n",
       "      <td>2.722251</td>\n",
       "      <td>CD_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-2.410286</td>\n",
       "      <td>2.410286</td>\n",
       "      <td>PRP_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-2.396420</td>\n",
       "      <td>2.396420</td>\n",
       "      <td>PRP$_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.986782</td>\n",
       "      <td>1.986782</td>\n",
       "      <td>VBN_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-1.864823</td>\n",
       "      <td>1.864823</td>\n",
       "      <td>WRB_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-1.799065</td>\n",
       "      <td>1.799065</td>\n",
       "      <td>DT_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.779174</td>\n",
       "      <td>1.779174</td>\n",
       "      <td>NN_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-1.775461</td>\n",
       "      <td>1.775461</td>\n",
       "      <td>WRB_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.697581</td>\n",
       "      <td>1.697581</td>\n",
       "      <td>IN_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-1.695893</td>\n",
       "      <td>1.695893</td>\n",
       "      <td>JJS_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.623625</td>\n",
       "      <td>1.623625</td>\n",
       "      <td>JJ_title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef  coef_abs                feat\n",
       "24 -3.542671  3.542671          PRP$_title\n",
       "55  3.161655  3.161655           NNPS_desc\n",
       "42 -3.045602  3.045602             CC_desc\n",
       "6   2.939313  2.939313  avg_word_len_title\n",
       "43  2.722251  2.722251             CD_desc\n",
       "59 -2.410286  2.410286            PRP_desc\n",
       "60 -2.396420  2.396420           PRP$_desc\n",
       "71  1.986782  1.986782            VBN_desc\n",
       "77 -1.864823  1.864823            WRB_desc\n",
       "44 -1.799065  1.799065             DT_desc\n",
       "53  1.779174  1.779174             NN_desc\n",
       "41 -1.775461  1.775461           WRB_title\n",
       "47  1.697581  1.697581             IN_desc\n",
       "50 -1.695893  1.695893            JJS_desc\n",
       "13  1.623625  1.623625            JJ_title"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(list(pipe.steps[0][1].coef_[0]), np.abs(list(pipe.steps[0][1].coef_[0])), X.columns)),\n",
    "             columns=['coef','coef_abs','feat']).sort_values('coef_abs', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text.to_csv('text.csv')\n",
    "# df.to_csv('df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Pipeline:\n",
    "X = pd.concat([text['combined'], df[[col for col in df.columns if col != 'yes_right']]], axis=1)\n",
    "y = df['yes_right']\n",
    "num_cols = [col for col in X.columns if col != 'combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DfExtract(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if len(self.column) > 1:\n",
    "            return pd.DataFrame(X[self.column])\n",
    "        else:\n",
    "            return pd.Series(X[self.column[0]]) \n",
    "    def get_feature_names(self):\n",
    "        return X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipe = Pipeline([\n",
    "            ('ext', DfExtract(['combined'])),\n",
    "            ('tf', TfidfVectorizer(preprocessor=lemmatizer.lemmatize,\n",
    "#                                    tokenizer=tokenizer.tokenize,\n",
    "                                   stop_words=cust_stop_words, min_df=3,\n",
    "                                   ngram_range=(2,4), use_idf=True, binary=False)\n",
    "            ),\n",
    "#             ('lda', TruncatedSVD(n_components=1000))\n",
    "        ])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "            ('ext', DfExtract(num_cols)),\n",
    "#             ('poly', PolynomialFeatures(interaction_only=True))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_union = FeatureUnion([\n",
    "        ('text', text_pipe),\n",
    "        ('numerical', num_pipe)]\n",
    "#     transformer_weights={'text': 2, 'numerical': 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('features', feat_union),\n",
    "#     ('lda', TruncatedSVD(n_components=100)),\n",
    "#     ('lr', LogisticRegression(random_state=42)),\n",
    "    ('pac', PassiveAggressiveClassifier(fit_intercept=True, random_state=42))\n",
    "#     ('mnb', MultinomialNB())\n",
    "#     ('svc', SVC(random_state=42))\n",
    "#     ('bnb', BernoulliNB(binarize=0.5))\n",
    "#     ('rf', RandomForestClassifier(random_state=42))\n",
    "#     ('sgdc', SGDClassifier(random_state=42))\n",
    "#     ('gbc', GradientBoostingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#     'lr__penalty': ['l1','l2'],\n",
    "#     'lr__C': [0.33, 0.5, 0.75, 1.0],\n",
    "#     'svc__kernel': ['rbf', 'sigmoid', 'poly'],\n",
    "#     'bnb__alpha': [1.0, 0.5, 0.33]\n",
    "    'pac__C': [0.35, 0.45, 0.5, 0.6, 0.75, 1],\n",
    "    'pac__loss': ['hinge','squared_hinge'],\n",
    "    'pac__average': [True, False]\n",
    "#     'mnb__alpha': [0.001, 0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "#     'rf__n_estimators': [20, 30],\n",
    "#     'rf__max_features': ['auto', 0.3],\n",
    "#     'rf__max_depth': [None, 4, 7]\n",
    "#     'sgdc__loss': ['log','perceptron'],\n",
    "#     'sgdc__penalty': ['l2','elasticnet'],\n",
    "#     'sgdc__alpha': [0.00001, 0.0001, 0.001]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(memory=None,\n",
       "     steps=[('ext', DfExtract(column=['combined'])), ('tf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',...     n_jobs=1, random_state=42, shuffle=True, tol=None, verbose=0,\n",
       "              warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'pac__C': [0.35, 0.45, 0.5, 0.6, 0.75, 1], 'pac__loss': ['hinge', 'squared_hinge'], 'pac__average': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129884225759769"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76796179726503144"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pac__C': 0.35, 'pac__average': True, 'pac__loss': 'hinge'}"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best scores: \n",
    "- PAC, 0.804: (1,4) ngrams, stemmer, polynomial off\n",
    "- PAC, 0.842: (1,4) ngrams, lemmatizer, poly off\n",
    "- LogReg, 0.808 : (1,4) ngrams, lemmatizer, poly off (and same score poly on int only)\n",
    "- PAC, 0.816: (1,4) ngrams, lemmatizer, poly on int only\n",
    "- PAC, 0.8399: (1,4) lemma, poly off, idf off binary false, transformer weights 3, 1\n",
    "- SGDC, 0.813: (1,4) ngrams, lemmatizer, poly off, 'loss': 'perceptron', 'penalty': 'l2' -- overfit\n",
    "- SGDC, 0.831: (1,4) ngrams, lemma, poly off, alpha': 0.01, 'loss': 'perceptron', 'penalty': 'l2'\n",
    "- MNB: 0.824 (1,4), lemma, poly off, alpha 0.025, tfidf off, binary true\n",
    "- PAC: 0.843 (1,4), lemma, poly off, C .45, binary true idf off, trans weights 2, 1\n",
    "- SGDC .825, percep, l2, 0.001 alpha, tfidf off binary true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How well does the model work for each news source?\n",
    "Make function with input source name, or for loop through `source.unique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low, high = min(text[text['source'] == 'Breitbart'].index), max(text[text['source'] == 'Breitbart'].index)\n",
    "# source_text = text[text['source'] == 'Breitbart']['combined']\n",
    "# source_num = df.iloc[low:high][num_cols]\n",
    "# s_label = text[text['source'] == 'Breitbart']['yes_right']\n",
    "# poop = pd.concat([source_text, source_num], axis=1)\n",
    "# poop = feat_union.fit_transform(poop)\n",
    "# gs.score(poop, s_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def source_score(model, source):\n",
    "#     low, high = min(text[text['source'] == source].index), max(text[text['source'] == source].index)\n",
    "#     source_text = text[text['source'] == source]['combined']\n",
    "#     source_num = df.iloc[low:high][num_cols]\n",
    "#     label = text[text['source'] == source]['yes_right']\n",
    "#     X = pd.concat([source_text, source_num], axis=1)\n",
    "#     X = feat_union.fit_transform(X)\n",
    "#     return model.score(X, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = text_pipe.fit(X_train, y_train).steps[1][1].get_feature_names()\n",
    "feature_names.extend(num_pipe.fit(X_train, y_train).steps[0][1].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_coefs = list(gs.best_estimator_.steps[1][1].coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33098 = 33097 ?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(len(feature_names), '=', len(pipe_coefs), '?')\n",
    "print(len(feature_names)==len(pipe_coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00 jpg'"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names.remove(feature_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33097 = 33097 ?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(feature_names), '=', len(pipe_coefs), '?')\n",
    "print(len(feature_names)==len(pipe_coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(list(zip(feature_names, pipe_coefs, np.abs(pipe_coefs))),\n",
    "                          columns=['feature','coef','abs_coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15254</th>\n",
       "      <td>Stephanie Ruhle Ali</td>\n",
       "      <td>-3.748326</td>\n",
       "      <td>3.748326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31581</th>\n",
       "      <td>talks Rachel Donald</td>\n",
       "      <td>-3.586563</td>\n",
       "      <td>3.586563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16151</th>\n",
       "      <td>The Latest Italy</td>\n",
       "      <td>3.449701</td>\n",
       "      <td>3.449701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>Ali Velshi Stephanie</td>\n",
       "      <td>-3.291323</td>\n",
       "      <td>3.291323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>Fast Facts Read</td>\n",
       "      <td>-2.891537</td>\n",
       "      <td>2.891537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15609</th>\n",
       "      <td>TEL AVIV An</td>\n",
       "      <td>2.885436</td>\n",
       "      <td>2.885436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>Ari Melber Fallback</td>\n",
       "      <td>-2.774018</td>\n",
       "      <td>2.774018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20310</th>\n",
       "      <td>Your World Generation</td>\n",
       "      <td>2.772057</td>\n",
       "      <td>2.772057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11258</th>\n",
       "      <td>News News China</td>\n",
       "      <td>2.717633</td>\n",
       "      <td>2.717633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>Michael Cohen 130</td>\n",
       "      <td>-2.706944</td>\n",
       "      <td>2.706944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>Charles Krauthammer Dead</td>\n",
       "      <td>2.699714</td>\n",
       "      <td>2.699714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>Rachel reviews</td>\n",
       "      <td>-2.683259</td>\n",
       "      <td>2.683259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13062</th>\n",
       "      <td>Raw video Police</td>\n",
       "      <td>2.597430</td>\n",
       "      <td>2.597430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>Fake News Media</td>\n",
       "      <td>2.462794</td>\n",
       "      <td>2.462794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19173</th>\n",
       "      <td>Vivienne Westwood</td>\n",
       "      <td>2.426501</td>\n",
       "      <td>2.426501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19126</th>\n",
       "      <td>Video shows</td>\n",
       "      <td>-2.402911</td>\n",
       "      <td>2.402911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23967</th>\n",
       "      <td>far left extremist</td>\n",
       "      <td>2.356778</td>\n",
       "      <td>2.356778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13799</th>\n",
       "      <td>Rudy Giuliani President</td>\n",
       "      <td>-2.348827</td>\n",
       "      <td>2.348827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>Fox amp Friends</td>\n",
       "      <td>2.186400</td>\n",
       "      <td>2.186400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8882</th>\n",
       "      <td>Katy Tur speaks</td>\n",
       "      <td>-2.175364</td>\n",
       "      <td>2.175364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature      coef  abs_coef\n",
       "15254       Stephanie Ruhle Ali -3.748326  3.748326\n",
       "31581       talks Rachel Donald -3.586563  3.586563\n",
       "16151          The Latest Italy  3.449701  3.449701\n",
       "1089       Ali Velshi Stephanie -3.291323  3.291323\n",
       "5378            Fast Facts Read -2.891537  2.891537\n",
       "15609               TEL AVIV An  2.885436  2.885436\n",
       "1631        Ari Melber Fallback -2.774018  2.774018\n",
       "20310     Your World Generation  2.772057  2.772057\n",
       "11258           News News China  2.717633  2.717633\n",
       "10259         Michael Cohen 130 -2.706944  2.706944\n",
       "2909   Charles Krauthammer Dead  2.699714  2.699714\n",
       "13011            Rachel reviews -2.683259  2.683259\n",
       "13062          Raw video Police  2.597430  2.597430\n",
       "5327            Fake News Media  2.462794  2.462794\n",
       "19173         Vivienne Westwood  2.426501  2.426501\n",
       "19126               Video shows -2.402911  2.402911\n",
       "23967        far left extremist  2.356778  2.356778\n",
       "13799   Rudy Giuliani President -2.348827  2.348827\n",
       "5907            Fox amp Friends  2.186400  2.186400\n",
       "8882            Katy Tur speaks -2.175364  2.175364"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.sort_values('abs_coef', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'WordCloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-10dc3109ce1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'WordCloud'"
     ]
    }
   ],
   "source": [
    "import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at probabilities \n",
    "\n",
    "feat_union.fit(X_train, y_train)\n",
    "X_test_transformed = feat_union.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PassiveAggressiveClassifier' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-619-cff252bb42d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'PassiveAggressiveClassifier' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "probabilities = gs.best_estimator_.steps[1][1].predict_proba(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b40ec5518>"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, [p[0] for p in probabilities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.90      0.84      4927\n",
      "          1       0.87      0.71      0.78      4287\n",
      "\n",
      "avg / total       0.82      0.81      0.81      9214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4458,  469],\n",
       "       [1251, 3036]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, gs.predict(X_test)) # false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs.best_estimator_.named_steps['features'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_coefs = pd.DataFrame(\n",
    "#     list(\n",
    "#         zip(X_test.columns, np.abs(\n",
    "#             coefs))), columns=['feature','coef_abs'])\n",
    "# lr_coefs.sort_values('coef_abs', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going to have to change this for feat union\n",
    "def manual_test():\n",
    "    title = input('Article title: \\n')\n",
    "    desc = input('Article description: \\n')\n",
    "    df = [{'title': '{}'.format(title),\n",
    "                'description': '{}'.format(desc)\n",
    "                }]\n",
    "    df=pd.DataFrame(df)\n",
    "    pred = gs.predict(df)\n",
    "    if pred == 1:\n",
    "        print(\"Result: Right wing\")\n",
    "    else:\n",
    "        print(\"Result: Not right wing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article title: \n",
      "Wait until midterms to choose next Supreme Court justice\n",
      "Article description: \n",
      "Mitch Mcconnell set a bad precedent \n",
      "Result: Not right wing\n"
     ]
    }
   ],
   "source": [
    "manual_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article title: \n",
      "Democratic candidates revolt against Pelosi in House races across the country\n",
      "Article description: \n",
      "Anyone looking for signs that Nancy Pelosi has lost clout within the Democratic ranks this cycle need only catch a glimpse of last week’s candidate forum in New Hampshire’s 1st Congressional District\n",
      "Result: Not right wing\n"
     ]
    }
   ],
   "source": [
    "manual_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text['title']\n",
    "y = text['yes_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(preprocessor=lemmatizer.lemmatize, stop_words=cust_stop_words, ngram_range=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train.todense())\n",
    "X_test = pd.DataFrame(X_test.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "test_X = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27640, 469477, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = None\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, \n",
    "               batch_input_shape=(batch_size, train_X.shape[1], train_X.shape[2]), \n",
    "               stateful=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27640 samples, validate on 9214 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_X, y_train, validation_data=(test_X, y_test), \n",
    "              epochs=10, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
