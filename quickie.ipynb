{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# procesando un chingo de la idioma natural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "# NLP Tools\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy as sp\n",
    "from textblob import TextBlob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = pd.read_csv('./datasets/jun20_bb_posts.csv', )\n",
    "cnn = pd.read_csv('./datasets/jun20_cnn_posts.csv')\n",
    "fox = pd.read_csv('./datasets/jun20_fox_posts.csv')\n",
    "fox2 = pd.read_csv('./datasets/fox_posts_jun26.csv')\n",
    "fox3 = pd.read_csv('./datasets/fox_posts_jun29.csv')\n",
    "nr = pd.read_csv('./datasets/jun20_nr_posts.csv')\n",
    "nr2 = pd.read_csv('./datasets/jun29_nr_posts.csv')\n",
    "# nyt = pd.read_csv('./datasets/jun20_nyt_posts.csv')\n",
    "vice = pd.read_csv('./datasets/jun20_vice_posts.csv')\n",
    "dem = pd.read_csv('./datasets/jun21_demnow_posts.csv')\n",
    "dem2 = pd.read_csv('./datasets/jun22_demnow_posts.csv')\n",
    "dem3 = pd.read_csv('./datasets/jun23_demnow_posts.csv')\n",
    "dem4 = pd.read_csv('./datasets/jun24_demnow_posts.csv')\n",
    "dem5 = pd.read_csv('./datasets/jun25_demnow_posts.csv')\n",
    "dem6 = pd.read_csv('./datasets/jun26_demnow_posts.csv')\n",
    "dem7 = pd.read_csv('./datasets/jun29_demnow_posts.csv')\n",
    "inwa = pd.read_csv('./datasets/june20infowars.csv')\n",
    "inwa2 = pd.read_csv('./datasets/june21infowars.csv')\n",
    "inwa3 = pd.read_csv('./datasets/june22infowars.csv')\n",
    "inwa4 = pd.read_csv('./datasets/june23infowars.csv')\n",
    "inwa5 = pd.read_csv('./datasets/june24infowars.csv')\n",
    "inwa6 = pd.read_csv('./datasets/june25infowars.csv')\n",
    "inwa7 = pd.read_csv('./datasets/june26infowars.csv')\n",
    "inwa8 = pd.read_csv('./datasets/june29infowars.csv')\n",
    "msnbc = pd.read_csv('./datasets/jun26_msnbc_posts.csv')\n",
    "huff = pd.read_csv('./datasets/jun_24_huff_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb['yes_right'] = 1\n",
    "cnn['yes_right'] = 0\n",
    "fox['yes_right'] = 1\n",
    "fox2['yes_right'] = 1\n",
    "fox3['yes_right'] = 1\n",
    "nr['yes_right'] = 1\n",
    "nr2['yes_right'] = 1\n",
    "# nyt['yes_right'] = 0\n",
    "vice['yes_right'] = 0\n",
    "dem['yes_right'] = 0\n",
    "dem2['yes_right'] = 0\n",
    "dem3['yes_right'] = 0\n",
    "dem4['yes_right'] = 0\n",
    "dem5['yes_right'] = 0\n",
    "dem6['yes_right'] = 0\n",
    "dem7['yes_right'] = 0\n",
    "inwa['yes_right'] = 1\n",
    "inwa2['yes_right'] = 1\n",
    "inwa3['yes_right'] = 1\n",
    "inwa4['yes_right'] = 1\n",
    "inwa5['yes_right'] = 1\n",
    "inwa6['yes_right'] = 1\n",
    "inwa7['yes_right'] = 1\n",
    "inwa8['yes_right'] = 1\n",
    "msnbc['yes_right'] = 0\n",
    "huff['yes_right'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.concat(\n",
    "    [bb, cnn, fox, fox2, fox3, nr, nr2, vice, dem, dem2, dem3, dem4, dem5, dem6, dem7, inwa,\n",
    "     inwa2, inwa3, inwa4, inwa5, inwa6, inwa7, inwa8, msnbc, huff])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.drop(['Unnamed: 0', 'category', 'urlToImage'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author         9466\n",
       "description      69\n",
       "publishedAt       0\n",
       "source            0\n",
       "title             1\n",
       "url               0\n",
       "yes_right         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_desc = text.description.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.dropna(subset=['description','title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author         9408\n",
       "description       0\n",
       "publishedAt       0\n",
       "source            0\n",
       "title             0\n",
       "url               0\n",
       "yes_right         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.fillna('no_author', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50578, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36854"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.url.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.drop_duplicates('url', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36854, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4652954903131275"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.yes_right.value_counts()[1]/len(text.yes_right) #baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fox news           6381\n",
       "national review    5348\n",
       "huffington post    4950\n",
       "msnbc              4950\n",
       "vice news          4949\n",
       "breitbart          4948\n",
       "cnn                4776\n",
       "infowars            471\n",
       "democracy now        81\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dict = {'breitbart': \"Breitbart\", 'cnn': \"CNN\", 'fox news': \"Fox News\",\n",
    "               'national review': \"National Review\", 'vice news': \"Vice News\", 'democracy now': \"Democracy Now\",\n",
    "               'infowars': \"Infowars\", 'msnbc': \"MSNBC\", 'huffington post': \"Huffington Post\"}\n",
    "\n",
    "text['source'] = text['source'].map(source_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in text.values:\n",
    "    author = row[0]\n",
    "    source = row[3]\n",
    "    row[1] = row[1].replace(author, '')\n",
    "    row[1] = row[1].replace(source, '')\n",
    "    row[1] = row[1].replace(author.lower(), '')\n",
    "    row[1] = row[1].replace(source.lower(), '')\n",
    "    row[4] = row[1].replace(author, '')\n",
    "    row[4] = row[1].replace(source, '')\n",
    "    row[4] = row[1].replace(author.lower(), '')\n",
    "    row[4] = row[1].replace(source.lower(), '')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['combined'] = text.title + ' ' + text.description # all text together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tokens = [tokenizer.tokenize(w) for w in text.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_word_length = []\n",
    "for title in title_tokens:\n",
    "    wordlen = []\n",
    "    for word in title:\n",
    "        wordlen.append(len(word))\n",
    "        if len(wordlen)==len(title):\n",
    "            avg_word_length.append(np.sum(wordlen)/len(wordlen))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36854"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['avg_word_len_title'] = avg_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['title_polarity'] = [TextBlob(w).sentiment.polarity for w in text.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['title_subjectivity'] = [TextBlob(w).sentiment.subjectivity for w in text.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['desc_polarity'] = [TextBlob(w).sentiment.polarity for w in text.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['desc_subjectivity'] = [TextBlob(w).sentiment.subjectivity for w in text.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['title_polarity'] = (text.title_polarity - min(text.title_polarity))/(max(text.title_polarity)-min(text.title_polarity))\n",
    "text['desc_polarity'] = (text.desc_polarity - min(text.desc_polarity))/(max(text.desc_polarity)-min(text.desc_polarity))\n",
    "# manual minmax scaler; i do not want negative values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text['subj_difference'] = text['title_subjectivity'] - text['desc_subjectivity']\n",
    "text['polarity_difference']  = text['title_polarity'] - text['desc_polarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags = [TextBlob(w.lower(), tokenizer=tokenizer).tags for w in text.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('peter', 'NN'),\n",
       " ('fonda', 'NN'),\n",
       " ('lying', 'VBG'),\n",
       " ('gash', 'JJ'),\n",
       " ('kirstjen', 'NNS'),\n",
       " ('nielsen', 'VBN'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('whipped', 'VBN'),\n",
       " ('naked', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('public', 'JJ')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_counts = []\n",
    "for row in title_tags:\n",
    "    tags = [n[1] for n in row]\n",
    "    tags_counts.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_parts_of_speech = []\n",
    "for n in tags_counts:\n",
    "    foo = dict(pd.Series(n).value_counts(normalize=True))\n",
    "    title_parts_of_speech.append(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_parts_of_speech = pd.DataFrame(title_parts_of_speech).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>MD</th>\n",
       "      <th>...</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CC   CD        DT   EX   FW        IN        JJ  JJR  JJS        MD ...   \\\n",
       "0  0.0  0.0  0.000000  0.0  0.0  0.083333  0.250000  0.0  0.0  0.083333 ...    \n",
       "1  0.0  0.0  0.000000  0.0  0.0  0.083333  0.250000  0.0  0.0  0.083333 ...    \n",
       "2  0.0  0.0  0.000000  0.0  0.0  0.000000  0.363636  0.0  0.0  0.000000 ...    \n",
       "3  0.0  0.0  0.000000  0.0  0.0  0.125000  0.125000  0.0  0.0  0.000000 ...    \n",
       "4  0.0  0.0  0.090909  0.0  0.0  0.272727  0.090909  0.0  0.0  0.000000 ...    \n",
       "\n",
       "         VB  VBD       VBG       VBN  VBP  VBZ  WDT   WP  WP$  WRB  \n",
       "0  0.083333  0.0  0.083333  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.083333  0.0  0.083333  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.090909  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.250000  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.000000  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_parts_of_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14285714285714285,\n",
       " 0.29642857142857143,\n",
       " 1.4419413919413919,\n",
       " 1.7037360300518194,\n",
       " 4.5128791959674306,\n",
       " 9.5963090830737876,\n",
       " 12.561901677613751,\n",
       " 12.975215367707627,\n",
       " 21.887959024120015,\n",
       " 26.311972851087564]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([title_parts_of_speech[col].sum() for col in title_parts_of_speech.columns])[:10]\n",
    "# Any columns with negligible values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_parts_of_speech.columns = [str(n) + '_title' for n in title_parts_of_speech.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NN_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.344309</td>\n",
       "      <td>0.161561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JJ_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.120518</td>\n",
       "      <td>0.104608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.096176</td>\n",
       "      <td>0.079306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NNS_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.094811</td>\n",
       "      <td>0.099862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_title</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>0.045403</td>\n",
       "      <td>0.070085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count      mean       std  min       25%       50%       75%  \\\n",
       "NN_title   36854.0  0.344309  0.161561  0.0  0.230769  0.333333  0.444444   \n",
       "JJ_title   36854.0  0.120518  0.104608  0.0  0.000000  0.111111  0.181818   \n",
       "IN_title   36854.0  0.096176  0.079306  0.0  0.000000  0.100000  0.142857   \n",
       "NNS_title  36854.0  0.094811  0.099862  0.0  0.000000  0.083333  0.142857   \n",
       "DT_title   36854.0  0.045403  0.070085  0.0  0.000000  0.000000  0.090909   \n",
       "\n",
       "                max  \n",
       "NN_title   1.000000  \n",
       "JJ_title   1.000000  \n",
       "IN_title   0.666667  \n",
       "NNS_title  1.000000  \n",
       "DT_title   0.500000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_parts_of_speech.describe().T.sort_values('mean', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_tags = [TextBlob(w, tokenizer=tokenizer).tags for w in text.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_counts = []\n",
    "for row in desc_tags:\n",
    "    tags = [n[1] for n in row]\n",
    "    tags_counts.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_parts_of_speech = []\n",
    "for n in tags_counts:\n",
    "    foo = dict(pd.Series(n).value_counts(normalize=True))\n",
    "    desc_parts_of_speech.append(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_parts_of_speech = pd.DataFrame(desc_parts_of_speech).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>DT</th>\n",
       "      <th>EX</th>\n",
       "      <th>FW</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>LS</th>\n",
       "      <th>...</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>WDT</th>\n",
       "      <th>WP</th>\n",
       "      <th>WP$</th>\n",
       "      <th>WRB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CC   CD        DT   EX   FW        IN        JJ  JJR       JJS   LS  \\\n",
       "0  0.000000  0.0  0.068182  0.0  0.0  0.090909  0.022727  0.0  0.000000  0.0   \n",
       "1  0.040000  0.0  0.000000  0.0  0.0  0.080000  0.080000  0.0  0.000000  0.0   \n",
       "2  0.040000  0.0  0.120000  0.0  0.0  0.100000  0.060000  0.0  0.000000  0.0   \n",
       "3  0.034483  0.0  0.103448  0.0  0.0  0.103448  0.137931  0.0  0.000000  0.0   \n",
       "4  0.000000  0.0  0.085714  0.0  0.0  0.114286  0.114286  0.0  0.028571  0.0   \n",
       "\n",
       "  ...         VB       VBD       VBG       VBN       VBP       VBZ  WDT  \\\n",
       "0 ...   0.022727  0.068182  0.045455  0.022727  0.000000  0.000000  0.0   \n",
       "1 ...   0.000000  0.000000  0.160000  0.040000  0.000000  0.040000  0.0   \n",
       "2 ...   0.080000  0.020000  0.060000  0.020000  0.100000  0.040000  0.0   \n",
       "3 ...   0.068966  0.034483  0.068966  0.000000  0.000000  0.034483  0.0   \n",
       "4 ...   0.000000  0.028571  0.057143  0.028571  0.057143  0.000000  0.0   \n",
       "\n",
       "         WP  WP$  WRB  \n",
       "0  0.022727  0.0  0.0  \n",
       "1  0.000000  0.0  0.0  \n",
       "2  0.000000  0.0  0.0  \n",
       "3  0.000000  0.0  0.0  \n",
       "4  0.000000  0.0  0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_parts_of_speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_parts_of_speech.columns = [str(n) + '_desc' for n in desc_parts_of_speech.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_parts_of_speech.shape[0] == title_parts_of_speech.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = pd.concat([title_parts_of_speech, desc_parts_of_speech], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'description', 'publishedAt', 'source', 'title', 'url',\n",
       "       'yes_right', 'combined', 'avg_word_len_title', 'title_polarity',\n",
       "       'title_subjectivity', 'desc_polarity', 'desc_subjectivity',\n",
       "       'subj_difference', 'polarity_difference'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>desc_polarity</th>\n",
       "      <th>desc_subjectivity</th>\n",
       "      <th>subj_difference</th>\n",
       "      <th>polarity_difference</th>\n",
       "      <th>avg_word_len_title</th>\n",
       "      <th>CC_title</th>\n",
       "      <th>CD_title</th>\n",
       "      <th>DT_title</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD_desc</th>\n",
       "      <th>VBG_desc</th>\n",
       "      <th>VBN_desc</th>\n",
       "      <th>VBP_desc</th>\n",
       "      <th>VBZ_desc</th>\n",
       "      <th>WDT_desc</th>\n",
       "      <th>WP_desc</th>\n",
       "      <th>WP$_desc</th>\n",
       "      <th>WRB_desc</th>\n",
       "      <th>yes_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.555417</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-0.155417</td>\n",
       "      <td>6.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_polarity  title_subjectivity  desc_polarity  desc_subjectivity  \\\n",
       "0            0.50            0.233333       0.500000           0.000000   \n",
       "1            0.25            0.900000       0.250000           0.650000   \n",
       "2            0.40            0.300000       0.555417           0.666667   \n",
       "\n",
       "   subj_difference  polarity_difference  avg_word_len_title  CC_title  \\\n",
       "0         0.233333             0.000000            5.166667       0.0   \n",
       "1         0.250000             0.000000            5.750000       0.0   \n",
       "2        -0.366667            -0.155417            6.545455       0.0   \n",
       "\n",
       "   CD_title  DT_title    ...      VBD_desc  VBG_desc  VBN_desc  VBP_desc  \\\n",
       "0       0.0       0.0    ...      0.068182  0.045455  0.022727       0.0   \n",
       "1       0.0       0.0    ...      0.000000  0.160000  0.040000       0.0   \n",
       "2       0.0       0.0    ...      0.020000  0.060000  0.020000       0.1   \n",
       "\n",
       "   VBZ_desc  WDT_desc   WP_desc  WP$_desc  WRB_desc  yes_right  \n",
       "0      0.00       0.0  0.022727       0.0       0.0          1  \n",
       "1      0.04       0.0  0.000000       0.0       0.0          1  \n",
       "2      0.04       0.0  0.000000       0.0       0.0          1  \n",
       "\n",
       "[3 rows x 79 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([text[['title_polarity', 'title_subjectivity', 'desc_polarity', 'desc_subjectivity', \n",
    "                      'subj_difference', 'polarity_difference', 'avg_word_len_title']], pos_tags, text.yes_right],\n",
    "               axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subj_difference</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>-0.094586</td>\n",
       "      <td>0.383313</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.065054</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_difference</th>\n",
       "      <td>36854.0</td>\n",
       "      <td>-0.015985</td>\n",
       "      <td>0.147947</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count      mean       std  min       25%       50%  \\\n",
       "subj_difference      36854.0 -0.094586  0.383313 -1.0 -0.350000 -0.041667   \n",
       "polarity_difference  36854.0 -0.015985  0.147947 -1.0 -0.083333  0.000000   \n",
       "\n",
       "                          75%  max  \n",
       "subj_difference      0.065054  1.0  \n",
       "polarity_difference  0.038194  0.9  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['subj_difference','polarity_difference']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj_difference\n",
      "polarity_difference\n",
      "avg_word_len_title\n"
     ]
    }
   ],
   "source": [
    "def scaled_checker(df):\n",
    "    for col in df.columns:\n",
    "        if max(df[col]) > 1:\n",
    "            print(col)\n",
    "        if min(df[col]) < 0:\n",
    "            print(col)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "scaled_checker(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subj_difference'] = (df['subj_difference'] - min(df['subj_difference']))/(max(df['subj_difference'])-min(df['subj_difference']))\n",
    "df['polarity_difference'] = (df['polarity_difference'] - min(df['polarity_difference']))/(max(df['polarity_difference'])-min(df['polarity_difference']))\n",
    "df['avg_word_len_title'] = (df['avg_word_len_title'] - min(df['avg_word_len_title']))/(max(df['avg_word_len_title'])-min(df['avg_word_len_title']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_checker(df) # numerical data is scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorin\n",
    "\n",
    "> Note: some of these CountVect instances have a tokenizer, some don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightwing = df[df.yes_right==1]\n",
    "notrightwing = df[df.yes_right==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rightwing.title_polarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rightwing.desc_polarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(notrightwing.polarity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(rightwing.subjectivity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(notrightwing.subjectivity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>desc_polarity</th>\n",
       "      <th>desc_subjectivity</th>\n",
       "      <th>subj_difference</th>\n",
       "      <th>polarity_difference</th>\n",
       "      <th>CC_title</th>\n",
       "      <th>CD_title</th>\n",
       "      <th>DT_title</th>\n",
       "      <th>EX_title</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD_desc</th>\n",
       "      <th>VBG_desc</th>\n",
       "      <th>VBN_desc</th>\n",
       "      <th>VBP_desc</th>\n",
       "      <th>VBZ_desc</th>\n",
       "      <th>WDT_desc</th>\n",
       "      <th>WP_desc</th>\n",
       "      <th>WP$_desc</th>\n",
       "      <th>WRB_desc</th>\n",
       "      <th>yes_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.000000</td>\n",
       "      <td>17148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.507856</td>\n",
       "      <td>0.201348</td>\n",
       "      <td>0.524753</td>\n",
       "      <td>0.312785</td>\n",
       "      <td>0.444282</td>\n",
       "      <td>0.517423</td>\n",
       "      <td>0.008432</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>0.038060</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034257</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.020803</td>\n",
       "      <td>0.014852</td>\n",
       "      <td>0.029732</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113371</td>\n",
       "      <td>0.296501</td>\n",
       "      <td>0.107291</td>\n",
       "      <td>0.270642</td>\n",
       "      <td>0.180273</td>\n",
       "      <td>0.070814</td>\n",
       "      <td>0.032427</td>\n",
       "      <td>0.064051</td>\n",
       "      <td>0.070437</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039131</td>\n",
       "      <td>0.033099</td>\n",
       "      <td>0.031306</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>0.038369</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.012765</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.478975</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       title_polarity  title_subjectivity  desc_polarity  desc_subjectivity  \\\n",
       "count    17148.000000        17148.000000   17148.000000       17148.000000   \n",
       "mean         0.507856            0.201348       0.524753           0.312785   \n",
       "std          0.113371            0.296501       0.107291           0.270642   \n",
       "min          0.000000            0.000000       0.000000           0.000000   \n",
       "25%          0.500000            0.000000       0.500000           0.000000   \n",
       "50%          0.500000            0.000000       0.500000           0.300000   \n",
       "75%          0.500000            0.400000       0.568182           0.500000   \n",
       "max          1.000000            1.000000       1.000000           1.000000   \n",
       "\n",
       "       subj_difference  polarity_difference      CC_title      CD_title  \\\n",
       "count     17148.000000         17148.000000  17148.000000  17148.000000   \n",
       "mean          0.444282             0.517423      0.008432      0.022978   \n",
       "std           0.180273             0.070814      0.032427      0.064051   \n",
       "min           0.000000             0.000000      0.000000      0.000000   \n",
       "25%           0.325000             0.488722      0.000000      0.000000   \n",
       "50%           0.478975             0.526316      0.000000      0.000000   \n",
       "75%           0.500000             0.539474      0.000000      0.000000   \n",
       "max           1.000000             1.000000      0.500000      1.000000   \n",
       "\n",
       "           DT_title      EX_title    ...          VBD_desc      VBG_desc  \\\n",
       "count  17148.000000  17148.000000    ...      17148.000000  17148.000000   \n",
       "mean       0.038060      0.000310    ...          0.034257      0.024705   \n",
       "std        0.070437      0.005626    ...          0.039131      0.033099   \n",
       "min        0.000000      0.000000    ...          0.000000      0.000000   \n",
       "25%        0.000000      0.000000    ...          0.000000      0.000000   \n",
       "50%        0.000000      0.000000    ...          0.026316      0.000000   \n",
       "75%        0.071429      0.000000    ...          0.058824      0.043478   \n",
       "max        0.500000      0.200000    ...          0.500000      0.333333   \n",
       "\n",
       "           VBN_desc      VBP_desc      VBZ_desc      WDT_desc       WP_desc  \\\n",
       "count  17148.000000  17148.000000  17148.000000  17148.000000  17148.000000   \n",
       "mean       0.020803      0.014852      0.029732      0.002963      0.003808   \n",
       "std        0.031306      0.028934      0.038369      0.010380      0.012822   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.022222      0.000000      0.000000   \n",
       "75%        0.037037      0.023810      0.047619      0.000000      0.000000   \n",
       "max        0.333333      0.400000      0.333333      0.142857      0.200000   \n",
       "\n",
       "           WP$_desc      WRB_desc  yes_right  \n",
       "count  17148.000000  17148.000000    17148.0  \n",
       "mean       0.000142      0.002923        1.0  \n",
       "std        0.002227      0.012765        0.0  \n",
       "min        0.000000      0.000000        1.0  \n",
       "25%        0.000000      0.000000        1.0  \n",
       "50%        0.000000      0.000000        1.0  \n",
       "75%        0.000000      0.000000        1.0  \n",
       "max        0.071429      0.333333        1.0  \n",
       "\n",
       "[8 rows x 78 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rightwing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>desc_polarity</th>\n",
       "      <th>desc_subjectivity</th>\n",
       "      <th>subj_difference</th>\n",
       "      <th>polarity_difference</th>\n",
       "      <th>CC_title</th>\n",
       "      <th>CD_title</th>\n",
       "      <th>DT_title</th>\n",
       "      <th>EX_title</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD_desc</th>\n",
       "      <th>VBG_desc</th>\n",
       "      <th>VBN_desc</th>\n",
       "      <th>VBP_desc</th>\n",
       "      <th>VBZ_desc</th>\n",
       "      <th>WDT_desc</th>\n",
       "      <th>WP_desc</th>\n",
       "      <th>WP$_desc</th>\n",
       "      <th>WRB_desc</th>\n",
       "      <th>yes_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.000000</td>\n",
       "      <td>19706.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.520245</td>\n",
       "      <td>0.252814</td>\n",
       "      <td>0.535436</td>\n",
       "      <td>0.332736</td>\n",
       "      <td>0.460039</td>\n",
       "      <td>0.518320</td>\n",
       "      <td>0.010126</td>\n",
       "      <td>0.029525</td>\n",
       "      <td>0.051793</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.024497</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>0.019779</td>\n",
       "      <td>0.034302</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.124798</td>\n",
       "      <td>0.315929</td>\n",
       "      <td>0.117447</td>\n",
       "      <td>0.284190</td>\n",
       "      <td>0.200756</td>\n",
       "      <td>0.083520</td>\n",
       "      <td>0.029949</td>\n",
       "      <td>0.091624</td>\n",
       "      <td>0.069148</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.035787</td>\n",
       "      <td>0.032652</td>\n",
       "      <td>0.037831</td>\n",
       "      <td>0.041853</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>0.017139</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.479665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.316369</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       title_polarity  title_subjectivity  desc_polarity  desc_subjectivity  \\\n",
       "count    19706.000000        19706.000000   19706.000000       19706.000000   \n",
       "mean         0.520245            0.252814       0.535436           0.332736   \n",
       "std          0.124798            0.315929       0.117447           0.284190   \n",
       "min          0.000000            0.000000       0.000000           0.000000   \n",
       "25%          0.500000            0.000000       0.500000           0.000000   \n",
       "50%          0.500000            0.050000       0.500000           0.316369   \n",
       "75%          0.550000            0.487500       0.587500           0.500000   \n",
       "max          1.000000            1.000000       1.000000           1.000000   \n",
       "\n",
       "       subj_difference  polarity_difference      CC_title      CD_title  \\\n",
       "count     19706.000000         19706.000000  19706.000000  19706.000000   \n",
       "mean          0.460039             0.518320      0.010126      0.029525   \n",
       "std           0.200756             0.083520      0.029949      0.091624   \n",
       "min           0.000000             0.052632      0.000000      0.000000   \n",
       "25%           0.325000             0.479665      0.000000      0.000000   \n",
       "50%           0.479167             0.526316      0.000000      0.000000   \n",
       "75%           0.555556             0.552632      0.000000      0.000000   \n",
       "max           1.000000             0.960526      0.250000      0.750000   \n",
       "\n",
       "           DT_title      EX_title    ...          VBD_desc      VBG_desc  \\\n",
       "count  19706.000000  19706.000000    ...      19706.000000  19706.000000   \n",
       "mean       0.051793      0.000368    ...          0.036111      0.024497   \n",
       "std        0.069148      0.005880    ...          0.045032      0.035787   \n",
       "min        0.000000      0.000000    ...          0.000000      0.000000   \n",
       "25%        0.000000      0.000000    ...          0.000000      0.000000   \n",
       "50%        0.000000      0.000000    ...          0.024390      0.000000   \n",
       "75%        0.100000      0.000000    ...          0.062500      0.044444   \n",
       "max        0.500000      0.166667    ...          0.500000      0.666667   \n",
       "\n",
       "           VBN_desc      VBP_desc      VBZ_desc      WDT_desc       WP_desc  \\\n",
       "count  19706.000000  19706.000000  19706.000000  19706.000000  19706.000000   \n",
       "mean       0.018485      0.019779      0.034302      0.002931      0.004942   \n",
       "std        0.032652      0.037831      0.041853      0.011350      0.017139   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.025000      0.000000      0.000000   \n",
       "75%        0.033333      0.032258      0.058824      0.000000      0.000000   \n",
       "max        0.500000      0.428571      0.333333      0.142857      0.500000   \n",
       "\n",
       "           WP$_desc      WRB_desc  yes_right  \n",
       "count  19706.000000  19706.000000    19706.0  \n",
       "mean       0.000086      0.004543        0.0  \n",
       "std        0.001955      0.016730        0.0  \n",
       "min        0.000000      0.000000        0.0  \n",
       "25%        0.000000      0.000000        0.0  \n",
       "50%        0.000000      0.000000        0.0  \n",
       "75%        0.000000      0.000000        0.0  \n",
       "max        0.100000      0.500000        0.0  \n",
       "\n",
       "[8 rows x 78 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notrightwing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Grams for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = text['yes_right'] == 1\n",
    "notright = text['yes_right'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_title = text[right].title\n",
    "right_desc = text[right].description\n",
    "notright_title = text[notright].title\n",
    "notright_desc = text[notright].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = PorterStemmer()\n",
    "cvec = CountVectorizer(preprocessor=stem.stem, tokenizer=tokenizer.tokenize, ngram_range=(1,1), stop_words='english', min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec.fit(right_title)\n",
    "rt_counts = pd.DataFrame(cvec.transform(right_title).todense(),\n",
    "                       columns=cvec.get_feature_names())\n",
    "title_counts = rt_counts.sum(axis=0)\n",
    "title_counts = pd.DataFrame(title_counts.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(1,1), stop_words='english', min_df=10)\n",
    "cvec.fit(notright_title)\n",
    "nrt_counts = pd.DataFrame(cvec.transform(notright_title).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrt_counts = nrt_counts.sum(axis=0)\n",
    "title_counts['not right'] = nrt_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>3221</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2983</td>\n",
       "      <td>3873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>1503</td>\n",
       "      <td>1079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>1062</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>602</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report</th>\n",
       "      <td>578</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north</th>\n",
       "      <td>523</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea</th>\n",
       "      <td>503</td>\n",
       "      <td>401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>424</td>\n",
       "      <td>492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>399</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim</th>\n",
       "      <td>397</td>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit</th>\n",
       "      <td>393</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>383</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>353</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>352</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police</th>\n",
       "      <td>343</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border</th>\n",
       "      <td>330</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald</th>\n",
       "      <td>304</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>301</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immigration</th>\n",
       "      <td>283</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             right  not right\n",
       "s             3221        NaN\n",
       "trump         2983     3873.0\n",
       "new           1503     1079.0\n",
       "fox           1062       95.0\n",
       "t              602        NaN\n",
       "report         578      293.0\n",
       "north          523      414.0\n",
       "korea          503      401.0\n",
       "says           424      492.0\n",
       "u              399        NaN\n",
       "kim            397      347.0\n",
       "summit         393      283.0\n",
       "day            383      250.0\n",
       "president      353      273.0\n",
       "house          352      425.0\n",
       "police         343      126.0\n",
       "border         330      168.0\n",
       "donald         304      184.0\n",
       "white          301      348.0\n",
       "immigration    283      191.0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>2983</td>\n",
       "      <td>3873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>1503</td>\n",
       "      <td>1079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>424</td>\n",
       "      <td>492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>220</td>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>352</td>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north</th>\n",
       "      <td>523</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korea</th>\n",
       "      <td>503</td>\n",
       "      <td>401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohen</th>\n",
       "      <td>53</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>301</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim</th>\n",
       "      <td>397</td>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>207</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>81</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mueller</th>\n",
       "      <td>195</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gop</th>\n",
       "      <td>260</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>82</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>89</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>174</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report</th>\n",
       "      <td>578</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit</th>\n",
       "      <td>393</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>108</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         right  not right\n",
       "trump     2983     3873.0\n",
       "new       1503     1079.0\n",
       "says       424      492.0\n",
       "2018       220      430.0\n",
       "house      352      425.0\n",
       "north      523      414.0\n",
       "korea      503      401.0\n",
       "cohen       53      391.0\n",
       "white      301      348.0\n",
       "kim        397      347.0\n",
       "world      207      340.0\n",
       "18          81      339.0\n",
       "mueller    195      331.0\n",
       "gop        260      328.0\n",
       "just        82      326.0\n",
       "like        89      320.0\n",
       "video      174      299.0\n",
       "report     578      293.0\n",
       "summit     393      283.0\n",
       "women      108      278.0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts.sort_values('not right', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Grams for Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, tokenizer=tokenizer.tokenize, ngram_range=(1,1), stop_words='english', min_df=10)\n",
    "cvec.fit(right_desc)\n",
    "rd_counts = pd.DataFrame(cvec.transform(right_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "desc_counts = rd_counts.sum(axis=0)\n",
    "desc_counts = pd.DataFrame(desc_counts.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(1,1), stop_words='english', min_df=10)\n",
    "cvec.fit(notright_desc)\n",
    "nrd_counts = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrd_counts = nrd_counts.sum(axis=0)\n",
    "desc_counts['not right'] = nrd_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>3830</td>\n",
       "      <td>4756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>3215</td>\n",
       "      <td>2796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>3121</td>\n",
       "      <td>857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>2794</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>1480</td>\n",
       "      <td>2052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>1214</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>1205</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald</th>\n",
       "      <td>1111</td>\n",
       "      <td>1374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north</th>\n",
       "      <td>938</td>\n",
       "      <td>721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>909</td>\n",
       "      <td>527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>843</td>\n",
       "      <td>838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>739</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>734</td>\n",
       "      <td>768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police</th>\n",
       "      <td>701</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuesday</th>\n",
       "      <td>682</td>\n",
       "      <td>416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>632</td>\n",
       "      <td>830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border</th>\n",
       "      <td>626</td>\n",
       "      <td>451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim</th>\n",
       "      <td>621</td>\n",
       "      <td>528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>614</td>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>612</td>\n",
       "      <td>417.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           right  not right\n",
       "trump       3830     4756.0\n",
       "president   3215     2796.0\n",
       "news        3121      857.0\n",
       "fox         2794      180.0\n",
       "new         1480     2052.0\n",
       "house       1214     1033.0\n",
       "said        1205     1093.0\n",
       "donald      1111     1374.0\n",
       "north        938      721.0\n",
       "state        909      527.0\n",
       "says         843      838.0\n",
       "year         739      584.0\n",
       "white        734      768.0\n",
       "police       701      265.0\n",
       "tuesday      682      416.0\n",
       "people       632      830.0\n",
       "border       626      451.0\n",
       "kim          621      528.0\n",
       "week         614      458.0\n",
       "national     612      417.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>3830</td>\n",
       "      <td>4756.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>3215</td>\n",
       "      <td>2796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>1480</td>\n",
       "      <td>2052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald</th>\n",
       "      <td>1111</td>\n",
       "      <td>1374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>1205</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>1214</td>\n",
       "      <td>1033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>192</td>\n",
       "      <td>958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>3121</td>\n",
       "      <td>857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>843</td>\n",
       "      <td>838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>632</td>\n",
       "      <td>830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discuss</th>\n",
       "      <td>275</td>\n",
       "      <td>777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>734</td>\n",
       "      <td>768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north</th>\n",
       "      <td>938</td>\n",
       "      <td>721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michael</th>\n",
       "      <td>242</td>\n",
       "      <td>718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>424</td>\n",
       "      <td>623.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>739</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney</th>\n",
       "      <td>316</td>\n",
       "      <td>569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cohen</th>\n",
       "      <td>69</td>\n",
       "      <td>562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>administration</th>\n",
       "      <td>409</td>\n",
       "      <td>562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>407</td>\n",
       "      <td>561.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                right  not right\n",
       "trump            3830     4756.0\n",
       "president        3215     2796.0\n",
       "new              1480     2052.0\n",
       "donald           1111     1374.0\n",
       "said             1205     1093.0\n",
       "house            1214     1033.0\n",
       "cnn               192      958.0\n",
       "news             3121      857.0\n",
       "says              843      838.0\n",
       "people            632      830.0\n",
       "discuss           275      777.0\n",
       "white             734      768.0\n",
       "north             938      721.0\n",
       "michael           242      718.0\n",
       "day               424      623.0\n",
       "year              739      584.0\n",
       "attorney          316      569.0\n",
       "cohen              69      562.0\n",
       "administration    409      562.0\n",
       "time              407      561.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts.sort_values('not right', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGrams for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(2,2), stop_words='english', min_df=10)\n",
    "cvec.fit(right_title)\n",
    "rt_counts2 = pd.DataFrame(cvec.transform(right_title).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "title_counts2 = rt_counts2.sum(axis=0)\n",
    "title_counts2 = pd.DataFrame(title_counts2.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(2,2), stop_words='english', min_df=10)\n",
    "cvec.fit(notright_title)\n",
    "nrt_counts2 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrt_counts2 = nrt_counts2.sum(axis=0)\n",
    "title_counts2['not right'] = nrt_counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fox new</th>\n",
       "      <td>961</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea</th>\n",
       "      <td>417</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>303</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim jong</th>\n",
       "      <td>182</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>181</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>181</td>\n",
       "      <td>904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ig report</th>\n",
       "      <td>141</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supreme court</th>\n",
       "      <td>129</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim</th>\n",
       "      <td>121</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judicial activism</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day liberal</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>100</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>91</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox news</th>\n",
       "      <td>85</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   right  not right\n",
       "fox new              961        NaN\n",
       "north korea          417      386.0\n",
       "donald trump         303     1352.0\n",
       "kim jong             182      414.0\n",
       "white house          181      634.0\n",
       "president trump      181      904.0\n",
       "ig report            141        7.0\n",
       "supreme court        129       94.0\n",
       "trump kim            121       61.0\n",
       "judicial activism    104        NaN\n",
       "liberal judicial     104        NaN\n",
       "day liberal          104        NaN\n",
       "new york             100      420.0\n",
       "year old              91      201.0\n",
       "fox news              85      101.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>303</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>181</td>\n",
       "      <td>904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>181</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>100</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim jong</th>\n",
       "      <td>182</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michael cohen</th>\n",
       "      <td>25</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump administration</th>\n",
       "      <td>67</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea</th>\n",
       "      <td>417</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean</th>\n",
       "      <td>54</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel</th>\n",
       "      <td>28</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert mueller</th>\n",
       "      <td>16</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rudy giuliani</th>\n",
       "      <td>13</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united states</th>\n",
       "      <td>18</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormy daniels</th>\n",
       "      <td>45</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>91</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      right  not right\n",
       "donald trump            303     1352.0\n",
       "president trump         181      904.0\n",
       "white house             181      634.0\n",
       "new york                100      420.0\n",
       "kim jong                182      414.0\n",
       "michael cohen            25      405.0\n",
       "trump administration     67      400.0\n",
       "north korea             417      386.0\n",
       "north korean             54      254.0\n",
       "special counsel          28      236.0\n",
       "robert mueller           16      232.0\n",
       "rudy giuliani            13      224.0\n",
       "united states            18      223.0\n",
       "stormy daniels           45      213.0\n",
       "year old                 91      201.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts2.sort_values('not right', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGrams for Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(2,2), stop_words='english', min_df=10)\n",
    "cvec.fit(right_desc)\n",
    "rd_counts2 = pd.DataFrame(cvec.transform(right_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "desc_counts2 = rd_counts2.sum(axis=0)\n",
    "desc_counts2 = pd.DataFrame(desc_counts2.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(2,2), stop_words='english', min_df=10)\n",
    "cvec.fit(notright_desc)\n",
    "nrd_counts2 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrd_counts2 = nrd_counts2.sum(axis=0)\n",
    "desc_counts2['not right'] = nrd_counts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fox news</th>\n",
       "      <td>2463</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>1187</td>\n",
       "      <td>904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>1088</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president donald</th>\n",
       "      <td>932</td>\n",
       "      <td>673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>621</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>481</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim jong</th>\n",
       "      <td>474</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea</th>\n",
       "      <td>473</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>339</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united states</th>\n",
       "      <td>314</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean</th>\n",
       "      <td>313</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump administration</th>\n",
       "      <td>257</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breitbart news</th>\n",
       "      <td>252</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nationalreview com</th>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com wp</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      right  not right\n",
       "fox news               2463      101.0\n",
       "president trump        1187      904.0\n",
       "donald trump           1088     1352.0\n",
       "president donald        932      673.0\n",
       "white house             621      634.0\n",
       "new york                481      420.0\n",
       "kim jong                474      414.0\n",
       "north korea             473      386.0\n",
       "year old                339      201.0\n",
       "united states           314      223.0\n",
       "north korean            313      254.0\n",
       "trump administration    257      400.0\n",
       "breitbart news          252        NaN\n",
       "nationalreview com      240        NaN\n",
       "com wp                  238        NaN"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>donald trump</th>\n",
       "      <td>1088</td>\n",
       "      <td>1352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president trump</th>\n",
       "      <td>1187</td>\n",
       "      <td>904.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president donald</th>\n",
       "      <td>932</td>\n",
       "      <td>673.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house</th>\n",
       "      <td>621</td>\n",
       "      <td>634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>481</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kim jong</th>\n",
       "      <td>474</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michael cohen</th>\n",
       "      <td>45</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump administration</th>\n",
       "      <td>257</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea</th>\n",
       "      <td>473</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean</th>\n",
       "      <td>313</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel</th>\n",
       "      <td>169</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robert mueller</th>\n",
       "      <td>136</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rudy giuliani</th>\n",
       "      <td>65</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united states</th>\n",
       "      <td>314</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormy daniels</th>\n",
       "      <td>50</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      right  not right\n",
       "donald trump           1088     1352.0\n",
       "president trump        1187      904.0\n",
       "president donald        932      673.0\n",
       "white house             621      634.0\n",
       "new york                481      420.0\n",
       "kim jong                474      414.0\n",
       "michael cohen            45      405.0\n",
       "trump administration    257      400.0\n",
       "north korea             473      386.0\n",
       "north korean            313      254.0\n",
       "special counsel         169      236.0\n",
       "robert mueller          136      232.0\n",
       "rudy giuliani            65      224.0\n",
       "united states           314      223.0\n",
       "stormy daniels           50      213.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts2.sort_values('not right',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriGrams for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(3,3), stop_words='english', min_df=5)\n",
    "cvec.fit(right_title)\n",
    "rt_counts3 = pd.DataFrame(cvec.transform(right_title).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "title_counts3 = rt_counts3.sum(axis=0)\n",
    "title_counts3 = pd.DataFrame(title_counts3.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(3,3), stop_words='english', min_df=5)\n",
    "cvec.fit(notright_title)\n",
    "nrt_counts3 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrt_counts3 = nrt_counts3.sum(axis=0)\n",
    "title_counts3['not right'] = nrt_counts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day liberal judicial</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea summit</th>\n",
       "      <td>76</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim summit</th>\n",
       "      <td>66</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say fox new</th>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says fox new</th>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police say fox</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report fox new</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox news rundown</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>south china sea</th>\n",
       "      <td>26</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border patrol agents</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york times</th>\n",
       "      <td>23</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim jong</th>\n",
       "      <td>23</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judicial activism june</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cartoons day march</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           right  not right\n",
       "liberal judicial activism    104        NaN\n",
       "day liberal judicial         104        NaN\n",
       "north korea summit            76       38.0\n",
       "trump kim summit              66        8.0\n",
       "say fox new                   53        NaN\n",
       "says fox new                  37        NaN\n",
       "police say fox                34        NaN\n",
       "report fox new                29        NaN\n",
       "fox news rundown              27        NaN\n",
       "south china sea               26       13.0\n",
       "border patrol agents          24        NaN\n",
       "new york times                23      155.0\n",
       "trump kim jong                23       41.0\n",
       "judicial activism june        22        NaN\n",
       "cartoons day march            21        NaN"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts3.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new york times</th>\n",
       "      <td>23</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york city</th>\n",
       "      <td>7</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump legal team</th>\n",
       "      <td>5</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit north korea</th>\n",
       "      <td>5</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim jong</th>\n",
       "      <td>23</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump white house</th>\n",
       "      <td>8</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe high school</th>\n",
       "      <td>7</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santa fe high</th>\n",
       "      <td>9</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea summit</th>\n",
       "      <td>76</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald trump jr</th>\n",
       "      <td>14</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit kim jong</th>\n",
       "      <td>15</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meeting kim jong</th>\n",
       "      <td>14</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormy daniels lawyer</th>\n",
       "      <td>7</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero tolerance immigration</th>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>york attorney general</th>\n",
       "      <td>6</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            right  not right\n",
       "new york times                 23      155.0\n",
       "new york city                   7       60.0\n",
       "trump legal team                5       48.0\n",
       "summit north korea              5       42.0\n",
       "trump kim jong                 23       41.0\n",
       "trump white house               8       41.0\n",
       "fe high school                  7       39.0\n",
       "santa fe high                   9       38.0\n",
       "north korea summit             76       38.0\n",
       "donald trump jr                14       34.0\n",
       "summit kim jong                15       27.0\n",
       "meeting kim jong               14       26.0\n",
       "stormy daniels lawyer           7       26.0\n",
       "zero tolerance immigration      6       23.0\n",
       "york attorney general           6       18.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts3.sort_values('not right', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriGrams for Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(3,3), stop_words='english', min_df=5)\n",
    "cvec.fit(right_desc)\n",
    "rd_counts3 = pd.DataFrame(cvec.transform(right_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "desc_counts3 = rd_counts3.sum(axis=0)\n",
    "desc_counts3 = pd.DataFrame(desc_counts3.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(3,3), stop_words='english', min_df=5)\n",
    "cvec.fit(notright_desc)\n",
    "nrd_counts3 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrd_counts3 = nrd_counts3.sum(axis=0)\n",
    "desc_counts3['not right'] = nrd_counts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>president donald trump</th>\n",
       "      <td>926</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nationalreview com wp</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com www nationalreview</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp com www</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com wp content</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp content uploads</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www nationalreview com</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content uploads 2018</th>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jpg fit 1024</th>\n",
       "      <td>218</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024 2c597 ssl</th>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit 1024 2c597</th>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox amp friends</th>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox news channel</th>\n",
       "      <td>142</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictator kim jong</th>\n",
       "      <td>125</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york times</th>\n",
       "      <td>118</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        right  not right\n",
       "president donald trump    926      672.0\n",
       "nationalreview com wp     238        NaN\n",
       "com www nationalreview    238        NaN\n",
       "wp com www                238        NaN\n",
       "com wp content            238        NaN\n",
       "wp content uploads        238        NaN\n",
       "www nationalreview com    238        NaN\n",
       "content uploads 2018      233        NaN\n",
       "jpg fit 1024              218        NaN\n",
       "1024 2c597 ssl            216        NaN\n",
       "fit 1024 2c597            216        NaN\n",
       "fox amp friends           162        NaN\n",
       "fox news channel          142        NaN\n",
       "dictator kim jong         125       21.0\n",
       "new york times            118      155.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts3.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>president donald trump</th>\n",
       "      <td>926</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean leader</th>\n",
       "      <td>102</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york times</th>\n",
       "      <td>118</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leader kim jong</th>\n",
       "      <td>108</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean leader kim</th>\n",
       "      <td>91</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel robert</th>\n",
       "      <td>110</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counsel robert mueller</th>\n",
       "      <td>108</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbi director james</th>\n",
       "      <td>60</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director james comey</th>\n",
       "      <td>59</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lawyer michael cohen</th>\n",
       "      <td>15</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney general jeff</th>\n",
       "      <td>48</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general jeff sessions</th>\n",
       "      <td>48</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york city</th>\n",
       "      <td>102</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney michael cohen</th>\n",
       "      <td>9</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero tolerance policy</th>\n",
       "      <td>15</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        right  not right\n",
       "president donald trump    926      672.0\n",
       "north korean leader       102      158.0\n",
       "new york times            118      155.0\n",
       "leader kim jong           108      149.0\n",
       "korean leader kim          91      133.0\n",
       "special counsel robert    110      125.0\n",
       "counsel robert mueller    108      122.0\n",
       "fbi director james         60       81.0\n",
       "director james comey       59       81.0\n",
       "lawyer michael cohen       15       69.0\n",
       "attorney general jeff      48       64.0\n",
       "general jeff sessions      48       64.0\n",
       "new york city             102       60.0\n",
       "attorney michael cohen      9       59.0\n",
       "zero tolerance policy      15       57.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts3.sort_values('not right',ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuadGrams for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(4,4), stop_words='english', min_df=3)\n",
    "cvec.fit(right_title)\n",
    "rt_counts4 = pd.DataFrame(cvec.transform(right_title).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "title_counts4 = rt_counts4.sum(axis=0)\n",
    "title_counts4 = pd.DataFrame(title_counts4.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(4,4), stop_words='english', min_df=3)\n",
    "cvec.fit(notright_title)\n",
    "nrt_counts4 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrt_counts4 = nrt_counts4.sum(axis=0)\n",
    "title_counts4['not right'] = nrt_counts4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day liberal judicial activism</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>police say fox new</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism june</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism march</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism february</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal judicial activism april</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report says fox new</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>things caught eye today</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national review summer internship</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion notes melania trump</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korea kim jong</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sector union dues cas</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ms 13 gang members</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santa fe high school</th>\n",
       "      <td>7</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>public sector union dues</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    right  not right\n",
       "day liberal judicial activism         104        NaN\n",
       "police say fox new                     34        NaN\n",
       "liberal judicial activism june         22        NaN\n",
       "liberal judicial activism march        20        NaN\n",
       "liberal judicial activism february     19        NaN\n",
       "liberal judicial activism april        19        NaN\n",
       "report says fox new                    13        NaN\n",
       "things caught eye today                11        NaN\n",
       "national review summer internship       9        NaN\n",
       "fashion notes melania trump             9        NaN\n",
       "north korea kim jong                    9        NaN\n",
       "sector union dues cas                   7        NaN\n",
       "ms 13 gang members                      7        NaN\n",
       "santa fe high school                    7       38.0\n",
       "public sector union dues                7        NaN"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts4.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>santa fe high school</th>\n",
       "      <td>7</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york attorney general</th>\n",
       "      <td>6</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house correspondents dinner</th>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney general eric schneiderman</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summit north korea kim</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump meeting kim jong</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dhs secretary kirstjen nielsen</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elon musk boring company</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>designer kate spade dead</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waffle house shooting suspect</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero tolerance immigration polici</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump north korea summit</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santa fe school shooting</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtv movie tv award</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day liberal judicial activism</th>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    right  not right\n",
       "santa fe high school                    7       38.0\n",
       "new york attorney general               6       18.0\n",
       "white house correspondents dinner       5       12.0\n",
       "attorney general eric schneiderman      3        7.0\n",
       "summit north korea kim                  3        7.0\n",
       "trump meeting kim jong                  6        3.0\n",
       "dhs secretary kirstjen nielsen          3        3.0\n",
       "elon musk boring company                4        1.0\n",
       "designer kate spade dead                4        1.0\n",
       "waffle house shooting suspect           3        1.0\n",
       "zero tolerance immigration polici       4        0.0\n",
       "trump north korea summit                4        0.0\n",
       "santa fe school shooting                3        0.0\n",
       "mtv movie tv award                      3        0.0\n",
       "day liberal judicial activism         104        NaN"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counts4.sort_values('not right', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuadGrams for Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(4,4), stop_words=cust_stop_words, min_df=5)\n",
    "cvec.fit(right_desc)\n",
    "rd_counts4 = pd.DataFrame(cvec.transform(right_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "desc_counts4 = rd_counts4.sum(axis=0)\n",
    "desc_counts4 = pd.DataFrame(desc_counts4.sort_values(ascending = False), columns=['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem, ngram_range=(4,4), stop_words=cust_stop_words, min_df=5)\n",
    "cvec.fit(notright_desc)\n",
    "nrd_counts4 = pd.DataFrame(cvec.transform(notright_desc).todense(),\n",
    "                         columns=cvec.get_feature_names())\n",
    "nrd_counts4 = nrd_counts4.sum(axis=0)\n",
    "desc_counts4['not right'] = nrd_counts4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>com wp content uploads</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp com com wp</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com com wp content</th>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp content uploads 2018</th>\n",
       "      <td>233</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit 1024 2c597 ssl</th>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jpg fit 1024 2c597</th>\n",
       "      <td>209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dictator kim jong un</th>\n",
       "      <td>125</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leader kim jong un</th>\n",
       "      <td>108</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel robert mueller</th>\n",
       "      <td>108</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean dictator kim</th>\n",
       "      <td>94</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean dictator kim jong</th>\n",
       "      <td>94</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean leader kim</th>\n",
       "      <td>91</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean leader kim jong</th>\n",
       "      <td>90</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https i0 wp com</th>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i0 wp com com</th>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                right  not right\n",
       "com wp content uploads            238        NaN\n",
       "wp com com wp                     238        NaN\n",
       "com com wp content                238        NaN\n",
       "wp content uploads 2018           233        NaN\n",
       "fit 1024 2c597 ssl                216        NaN\n",
       "jpg fit 1024 2c597                209        NaN\n",
       "dictator kim jong un              125       21.0\n",
       "leader kim jong un                108      148.0\n",
       "special counsel robert mueller    108      122.0\n",
       "north korean dictator kim          94       17.0\n",
       "korean dictator kim jong           94       16.0\n",
       "north korean leader kim            91      133.0\n",
       "korean leader kim jong             90      132.0\n",
       "https i0 wp com                    83        NaN\n",
       "i0 wp com com                      83        NaN"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts4.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right</th>\n",
       "      <th>not right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leader kim jong un</th>\n",
       "      <td>108</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>north korean leader kim</th>\n",
       "      <td>91</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean leader kim jong</th>\n",
       "      <td>90</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special counsel robert mueller</th>\n",
       "      <td>108</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbi director james comey</th>\n",
       "      <td>59</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney general jeff sessions</th>\n",
       "      <td>48</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>former fbi director james</th>\n",
       "      <td>46</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white house press secretary</th>\n",
       "      <td>69</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secretary state mike pompeo</th>\n",
       "      <td>53</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump north korean leader</th>\n",
       "      <td>26</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump kim jong un</th>\n",
       "      <td>43</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santa fe high school</th>\n",
       "      <td>20</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us president donald trump</th>\n",
       "      <td>7</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house press secretary sarah</th>\n",
       "      <td>43</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first lady melania trump</th>\n",
       "      <td>60</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                right  not right\n",
       "leader kim jong un                108      148.0\n",
       "north korean leader kim            91      133.0\n",
       "korean leader kim jong             90      132.0\n",
       "special counsel robert mueller    108      122.0\n",
       "fbi director james comey           59       81.0\n",
       "attorney general jeff sessions     48       63.0\n",
       "former fbi director james          46       62.0\n",
       "white house press secretary        69       47.0\n",
       "secretary state mike pompeo        53       47.0\n",
       "trump north korean leader          26       45.0\n",
       "trump kim jong un                  43       41.0\n",
       "santa fe high school               20       38.0\n",
       "us president donald trump           7       36.0\n",
       "house press secretary sarah        43       35.0\n",
       "first lady melania trump           60       35.0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_counts4.sort_values('not right', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv('./text.csv').drop('Unnamed: 0', axis=1)\n",
    "df = pd.read_csv('./df.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\n",
    "                   \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself',\n",
    "                   'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
    "                   'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\",\n",
    "                   'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has',\n",
    "                   'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
    "                   'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against',\n",
    "                   'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from',\n",
    "                   'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once',\n",
    "                   'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "                   'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too',\n",
    "                   'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
    "                   'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn',\n",
    "                   \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    "                   \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n",
    "                   'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'cnn',\n",
    "                   'national review', 'huffpost','fox','reuters','ap', 'associated press', 'vice','breitbart',\n",
    "                   'nationalreview', 'www', 'content uploads', 'msnbc', 'infowars', 'foxnews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For text data only\n",
    "X = text['combined']\n",
    "y = text['yes_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(preprocessor=stem.stem,\n",
    "                       strip_accents='ascii',\n",
    "                       ngram_range=(1,4),\n",
    "                       stop_words=cust_stop_words,\n",
    "                       min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 4),\n",
       "        preprocessor=<bound method PorterStemmer.stem of <PorterStemmer>>,\n",
       "        stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs',...ciated press', 'vice', 'breitbart', 'nationalreview', 'www', 'content uploads', 'msnbc', 'infowars'],\n",
       "        strip_accents='ascii', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feats = pd.DataFrame(cvec.transform(X_train).todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trump              11672\n",
       "president           5049\n",
       "news                4050\n",
       "new                 3764\n",
       "house               2297\n",
       "donald              2249\n",
       "donald trump        2200\n",
       "says                2077\n",
       "north               1980\n",
       "former              1825\n",
       "president trump     1802\n",
       "said                1789\n",
       "white               1612\n",
       "first               1561\n",
       "one                 1554\n",
       "korea               1497\n",
       "us                  1454\n",
       "kim                 1429\n",
       "people              1419\n",
       "state               1357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = X_feats.sum(axis=0)\n",
    "word_counts.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train = cvec.transform(X_train).todense()\n",
    "cv_test = cvec.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_train = cvec.transform(X_train)\n",
    "# cv_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(cv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97206946454413889"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(cv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78369871934013458"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(cv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.82      0.80      4927\n",
      "          1       0.78      0.74      0.76      4287\n",
      "\n",
      "avg / total       0.78      0.78      0.78      9214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr.predict(cv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4057  870]\n",
      " [1123 3164]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, lr.predict(cv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73996105432433146"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, cv_test, y_test, cv=7, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = lr.coef_[0]\n",
    "fts = cvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>abs</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14678</th>\n",
       "      <td>news news</td>\n",
       "      <td>5.175507</td>\n",
       "      <td>5.175507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8109</th>\n",
       "      <td>fmr</td>\n",
       "      <td>2.748248</td>\n",
       "      <td>-2.748248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23929</th>\n",
       "      <td>visit post</td>\n",
       "      <td>2.291936</td>\n",
       "      <td>2.291936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>amp</td>\n",
       "      <td>2.259361</td>\n",
       "      <td>2.259361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14905</th>\n",
       "      <td>nolte</td>\n",
       "      <td>2.224639</td>\n",
       "      <td>2.224639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23196</th>\n",
       "      <td>tuck</td>\n",
       "      <td>2.214092</td>\n",
       "      <td>2.214092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5664</th>\n",
       "      <td>delingpole</td>\n",
       "      <td>2.168175</td>\n",
       "      <td>2.168175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>foxnews</td>\n",
       "      <td>2.146565</td>\n",
       "      <td>2.146565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8420</th>\n",
       "      <td>foxnews com</td>\n",
       "      <td>2.146565</td>\n",
       "      <td>2.146565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>broadcast</td>\n",
       "      <td>2.117388</td>\n",
       "      <td>2.117388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17577</th>\n",
       "      <td>raw video</td>\n",
       "      <td>2.053618</td>\n",
       "      <td>2.053618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12385</th>\n",
       "      <td>lgbtq</td>\n",
       "      <td>2.032883</td>\n",
       "      <td>-2.032883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15057</th>\n",
       "      <td>nr</td>\n",
       "      <td>2.026424</td>\n",
       "      <td>2.026424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9016</th>\n",
       "      <td>goodnewsruhles</td>\n",
       "      <td>1.968936</td>\n",
       "      <td>-1.968936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12492</th>\n",
       "      <td>links</td>\n",
       "      <td>1.951805</td>\n",
       "      <td>1.951805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22160</th>\n",
       "      <td>times local</td>\n",
       "      <td>1.878517</td>\n",
       "      <td>1.878517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10634</th>\n",
       "      <td>insight</td>\n",
       "      <td>1.846692</td>\n",
       "      <td>1.846692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14211</th>\n",
       "      <td>national review</td>\n",
       "      <td>1.797886</td>\n",
       "      <td>1.797886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>afp</td>\n",
       "      <td>1.770522</td>\n",
       "      <td>1.770522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>amp friends</td>\n",
       "      <td>1.753552</td>\n",
       "      <td>1.753552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9339</th>\n",
       "      <td>gutfeld</td>\n",
       "      <td>1.747047</td>\n",
       "      <td>1.747047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>censorship</td>\n",
       "      <td>1.738657</td>\n",
       "      <td>1.738657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17347</th>\n",
       "      <td>queer</td>\n",
       "      <td>1.721576</td>\n",
       "      <td>-1.721576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>big question</td>\n",
       "      <td>1.720396</td>\n",
       "      <td>-1.720396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20966</th>\n",
       "      <td>stephanie</td>\n",
       "      <td>1.717674</td>\n",
       "      <td>-1.717674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feat       abs      coef\n",
       "14678        news news  5.175507  5.175507\n",
       "8109               fmr  2.748248 -2.748248\n",
       "23929       visit post  2.291936  2.291936\n",
       "1406               amp  2.259361  2.259361\n",
       "14905            nolte  2.224639  2.224639\n",
       "23196             tuck  2.214092  2.214092\n",
       "5664        delingpole  2.168175  2.168175\n",
       "8419           foxnews  2.146565  2.146565\n",
       "8420       foxnews com  2.146565  2.146565\n",
       "3006         broadcast  2.117388  2.117388\n",
       "17577        raw video  2.053618  2.053618\n",
       "12385            lgbtq  2.032883 -2.032883\n",
       "15057               nr  2.026424  2.026424\n",
       "9016    goodnewsruhles  1.968936 -1.968936\n",
       "12492            links  1.951805  1.951805\n",
       "22160      times local  1.878517  1.878517\n",
       "10634          insight  1.846692  1.846692\n",
       "14211  national review  1.797886  1.797886\n",
       "972                afp  1.770522  1.770522\n",
       "1407       amp friends  1.753552  1.753552\n",
       "9339           gutfeld  1.747047  1.747047\n",
       "3590        censorship  1.738657  1.738657\n",
       "17347            queer  1.721576 -1.721576\n",
       "2528      big question  1.720396 -1.720396\n",
       "20966        stephanie  1.717674 -1.717674"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    list(zip(fts, np.abs(cfs), cfs)),\n",
    "    columns=['feat','abs','coef']).sort_values('abs',ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passive Aggressive Classifier** on Same CountVectorized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac = PassiveAggressiveClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93013748191027501"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.fit(cv_train, y_train)\n",
    "pac.score(cv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77176036466247011"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.score(cv_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PorterStemmer and TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(\n",
    "    strip_accents='ascii',\n",
    "    preprocessor=stemmer.stem,\n",
    "    ngram_range=(2,4),\n",
    "    stop_words=cust_stop_words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 4), norm='l2',\n",
       "        preprocessor=<bound method PorterStemmer.stem of <PorterStemmer>>,\n",
       "        smooth_idf=True,\n",
       "        stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs',...ciated press', 'vice', 'breitbart', 'nationalreview', 'www', 'content uploads', 'msnbc', 'infowars'],\n",
       "        strip_accents='ascii', sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train = tf.transform(X_train)\n",
    "tf_test = tf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'penalty': ['l2','l1'],\n",
    "    'C': [1.0,0.6]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(lr, parameters, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l2', 'l1'], 'C': [1.0, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99602026049204051"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7489689602778381"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(tf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.86      0.79      4927\n",
      "          1       0.79      0.62      0.70      4287\n",
      "\n",
      "avg / total       0.76      0.75      0.74      9214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid.predict(tf_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4226  701]\n",
      " [1612 2675]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, grid.predict(tf_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gettin passive aggressive with it now*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac = PassiveAggressiveClassifier()\n",
    "pac.fit(tf_train, y_train)\n",
    "pac.score(tf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77100065118298244"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.score(tf_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at Numerical Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[col for col in df.columns if col != 'yes_right']]\n",
    "y = df['yes_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74540520984081038, 0.60538311265465594)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_train, y_train), knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.61841534008683063, 0.61949207727371391)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "bnb.score(X_train, y_train), bnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.63256150506512299, 0.63256150506512299)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_train, y_train), lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('poly', PolynomialFeatures(degree=2, include_bias=True, interaction_only=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('model', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures(interaction_only=True)),\n",
    "    ('pca', PCA()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.64920405209840815, 0.65064032993271104)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train), pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_importance</th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.206694</td>\n",
       "      <td>DT_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.113385</td>\n",
       "      <td>avg_word_len_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.094110</td>\n",
       "      <td>PRP_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.082537</td>\n",
       "      <td>NN_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.058901</td>\n",
       "      <td>PRP$_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.049485</td>\n",
       "      <td>RB_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.037922</td>\n",
       "      <td>CD_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.037835</td>\n",
       "      <td>NNP_desc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.035881</td>\n",
       "      <td>NN_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.035665</td>\n",
       "      <td>VBZ_title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_importance                feat\n",
       "9          0.206694            DT_title\n",
       "6          0.113385  avg_word_len_title\n",
       "59         0.094110            PRP_desc\n",
       "53         0.082537             NN_desc\n",
       "24         0.058901          PRP$_title\n",
       "61         0.049485             RB_desc\n",
       "8          0.037922            CD_title\n",
       "54         0.037835            NNP_desc\n",
       "17         0.035881            NN_title\n",
       "37         0.035665           VBZ_title"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(pipe.steps[0][1].feature_importances_, X.columns)),\n",
    "             columns=['feat_importance','feat']).sort_values('feat_importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text.to_csv('text.csv')\n",
    "# df.to_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>desc_polarity</th>\n",
       "      <th>desc_subjectivity</th>\n",
       "      <th>subj_difference</th>\n",
       "      <th>polarity_difference</th>\n",
       "      <th>avg_word_len_title</th>\n",
       "      <th>CC_title</th>\n",
       "      <th>CD_title</th>\n",
       "      <th>DT_title</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD_desc</th>\n",
       "      <th>VBG_desc</th>\n",
       "      <th>VBN_desc</th>\n",
       "      <th>VBP_desc</th>\n",
       "      <th>VBZ_desc</th>\n",
       "      <th>WDT_desc</th>\n",
       "      <th>WP_desc</th>\n",
       "      <th>WP$_desc</th>\n",
       "      <th>WRB_desc</th>\n",
       "      <th>yes_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.555417</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.444518</td>\n",
       "      <td>0.396104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_polarity  title_subjectivity  desc_polarity  desc_subjectivity  \\\n",
       "0            0.50            0.233333       0.500000           0.000000   \n",
       "1            0.25            0.900000       0.250000           0.650000   \n",
       "2            0.40            0.300000       0.555417           0.666667   \n",
       "3            0.50            0.000000       0.800000           0.900000   \n",
       "4            0.50            0.000000       0.625000           0.671429   \n",
       "\n",
       "   subj_difference  polarity_difference  avg_word_len_title  CC_title  \\\n",
       "0         0.616667             0.526316            0.297619       0.0   \n",
       "1         0.625000             0.526316            0.339286       0.0   \n",
       "2         0.316667             0.444518            0.396104       0.0   \n",
       "3         0.050000             0.368421            0.250000       0.0   \n",
       "4         0.164286             0.460526            0.350649       0.0   \n",
       "\n",
       "   CD_title  DT_title    ...      VBD_desc  VBG_desc  VBN_desc  VBP_desc  \\\n",
       "0       0.0  0.000000    ...      0.068182  0.045455  0.022727  0.000000   \n",
       "1       0.0  0.000000    ...      0.000000  0.160000  0.040000  0.000000   \n",
       "2       0.0  0.000000    ...      0.020000  0.060000  0.020000  0.100000   \n",
       "3       0.0  0.000000    ...      0.034483  0.068966  0.000000  0.000000   \n",
       "4       0.0  0.090909    ...      0.028571  0.057143  0.028571  0.057143   \n",
       "\n",
       "   VBZ_desc  WDT_desc   WP_desc  WP$_desc  WRB_desc  yes_right  \n",
       "0  0.000000       0.0  0.022727       0.0       0.0          1  \n",
       "1  0.040000       0.0  0.000000       0.0       0.0          1  \n",
       "2  0.040000       0.0  0.000000       0.0       0.0          1  \n",
       "3  0.034483       0.0  0.000000       0.0       0.0          1  \n",
       "4  0.000000       0.0  0.000000       0.0       0.0          1  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Pipeline:\n",
    "X = pd.concat([text['combined'], df[[col for col in df.columns if col != 'yes_right']]], axis=1)\n",
    "y = df['yes_right']\n",
    "num_cols = [col for col in X.columns if col != 'combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DfExtract(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if len(self.column) > 1:\n",
    "            return pd.DataFrame(X[self.column])\n",
    "        else:\n",
    "            return pd.Series(X[self.column[0]]) \n",
    "#     def get_feature_names(self):\n",
    "#         return X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try making the weight for the text heavier than the numerical info\n",
    "\n",
    "feat_union = FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('ext', DfExtract(['combined'])),\n",
    "            ('tf', TfidfVectorizer(preprocessor=lemmatizer.lemmatize,\n",
    "                                   stop_words=cust_stop_words,\n",
    "                                   ngram_range=(2,4), use_idf=False, binary=True)\n",
    "            ),\n",
    "#             ('lsa', TruncatedSVD(n_components=1000))\n",
    "        ])),\n",
    "        ('numerical', Pipeline([\n",
    "            ('ext', DfExtract(num_cols)),\n",
    "#             ('poly', PolynomialFeatures(interaction_only=True))\n",
    "            ]))],\n",
    "#     transformer_weights={'text': 2, 'numerical': 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('features', feat_union),\n",
    "#     ('lsa', TruncatedSVD(n_components=100)),\n",
    "#     ('lr', LogisticRegression(random_state=42)),\n",
    "    ('pac', PassiveAggressiveClassifier(fit_intercept=True, random_state=42))\n",
    "#     ('mnb', MultinomialNB())\n",
    "#     ('svc', SVC(random_state=42))\n",
    "#     ('bnb', BernoulliNB(binarize=0.5))\n",
    "#     ('rf', RandomForestClassifier(random_state=42))\n",
    "#     ('sgdc', SGDClassifier(random_state=42))\n",
    "#     ('gbc', GradientBoostingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#     'lr__penalty': ['l1','l2'],\n",
    "#     'lr__C': [0.33, 0.5, 0.75, 1.0],\n",
    "#     'svc__kernel': ['rbf', 'sigmoid', 'poly'],\n",
    "#     'bnb__alpha': [1.0, 0.5, 0.33]\n",
    "    'pac__C': [0.35, 0.45, 0.5, 0.6, 0.75, 1],\n",
    "    'pac__loss': ['hinge','squared_hinge'],\n",
    "#     'pac__average': [True, False]\n",
    "#     'mnb__alpha': [0.001, 0.01, 0.025, 0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "#     'rf__n_estimators': [20, 30],\n",
    "#     'rf__max_features': ['auto', 0.3],\n",
    "#     'rf__max_depth': [None, 4, 7]\n",
    "#     'sgdc__loss': ['log','perceptron'],\n",
    "#     'sgdc__penalty': ['l2','elasticnet'],\n",
    "#     'sgdc__alpha': [0.00001, 0.0001, 0.001]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.passive_aggressive.PassiveAggressiveClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('text', Pipeline(memory=None,\n",
       "     steps=[('ext', DfExtract(column=['combined'])), ('tf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',...     n_jobs=1, random_state=42, shuffle=True, tol=None, verbose=0,\n",
       "              warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'pac__C': [0.33, 0.45, 0.5, 0.6, 0.75, 1], 'pac__loss': ['hinge', 'squared_hinge'], 'pac__average': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84208812676362055"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pac__C': 0.45, 'pac__average': False, 'pac__loss': 'hinge'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs.best_estimator_.named_steps['features'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_union.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best scores: \n",
    "- PAC, 0.804: (1,4) ngrams, stemmer, polynomial off\n",
    "- PAC, 0.842: (1,4) ngrams, lemmatizer, poly off\n",
    "- LogReg, 0.808 : (1,4) ngrams, lemmatizer, poly off (and same score poly on int only)\n",
    "- PAC, 0.816: (1,4) ngrams, lemmatizer, poly on int only\n",
    "- PAC, 0.8399: (1,4) lemma, poly off, idf off binary false, transformer weights 3, 1\n",
    "- SGDC, 0.813: (1,4) ngrams, lemmatizer, poly off, 'loss': 'perceptron', 'penalty': 'l2' -- overfit\n",
    "- SGDC, 0.831: (1,4) ngrams, lemma, poly off, alpha': 0.01, 'loss': 'perceptron', 'penalty': 'l2'\n",
    "- MNB: 0.824 (1,4), lemma, poly off, alpha 0.025, tfidf off, binary true\n",
    "- PAC: 0.843 (1,4), lemma, poly off, C .45, binary true idf off, trans weights 2, 1\n",
    "- SGDC .825, percep, l2, 0.001 alpha, tfidf off binary true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at probabilities \n",
    "\n",
    "feat_union.fit(X_train, y_train)\n",
    "X_test_transformed = feat_union.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.02083333,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.02777778,\n",
       "          0.        ,  0.02777778]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Transformer text (type Pipeline) does not provide get_feature_names.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f23d2ba93ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##### TRY GET FEATURE NAMES HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeat_union\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m                 raise AttributeError(\"Transformer %s (type %s) does not \"\n\u001b[1;32m    688\u001b[0m                                      \u001b[0;34m\"provide get_feature_names.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                                      % (str(name), type(trans).__name__))\n\u001b[0m\u001b[1;32m    690\u001b[0m             feature_names.extend([name + \"__\" + f for f in\n\u001b[1;32m    691\u001b[0m                                   trans.get_feature_names()])\n",
      "\u001b[0;31mAttributeError\u001b[0m: Transformer text (type Pipeline) does not provide get_feature_names."
     ]
    }
   ],
   "source": [
    "##### TRY GET FEATURE NAMES HERE\n",
    "\n",
    "feat_union.get_feature_names()\n",
    "\n",
    "##### SUCK MY FUCKIN ASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = gs.best_estimator_.steps[1][1].predict_proba(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ae7a2f7b8>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test.index, [p[0] for p in probabilities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = list(gs.best_estimator_.steps[1][1].coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1542016"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.90      0.84      4927\n",
      "          1       0.87      0.71      0.78      4287\n",
      "\n",
      "avg / total       0.82      0.81      0.81      9214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4458,  469],\n",
       "       [1251, 3036]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, gs.predict(X_test)) # false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs.best_estimator_.named_steps['features'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_coefs = pd.DataFrame(\n",
    "#     list(\n",
    "#         zip(X_test.columns, np.abs(\n",
    "#             coefs))), columns=['feature','coef_abs'])\n",
    "# lr_coefs.sort_values('coef_abs', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_test():\n",
    "    title = input('Article title: \\n')\n",
    "    desc = input('Article description: \\n')\n",
    "    df = [{'title': '{}'.format(title),\n",
    "                'description': '{}'.format(desc)\n",
    "                }]\n",
    "    df=pd.DataFrame(df)\n",
    "    pred = gs.predict(df)\n",
    "    if pred == 1:\n",
    "        print(\"Result: Right wing\")\n",
    "    else:\n",
    "        print(\"Result: Not right wing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article title: \n",
      "Wait until midterms to choose next Supreme Court justice\n",
      "Article description: \n",
      "Mitch Mcconnell set a bad precedent \n",
      "Result: Not right wing\n"
     ]
    }
   ],
   "source": [
    "manual_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article title: \n",
      "Democratic candidates revolt against Pelosi in House races across the country\n",
      "Article description: \n",
      "Anyone looking for signs that Nancy Pelosi has lost clout within the Democratic ranks this cycle need only catch a glimpse of last week’s candidate forum in New Hampshire’s 1st Congressional District\n",
      "Result: Not right wing\n"
     ]
    }
   ],
   "source": [
    "manual_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text['title']\n",
    "y = text['yes_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(preprocessor=lemmatizer.lemmatize, stop_words=cust_stop_words, ngram_range=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train.todense())\n",
    "X_test = pd.DataFrame(X_test.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "test_X = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27640, 469477, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = None\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, \n",
    "               batch_input_shape=(batch_size, train_X.shape[1], train_X.shape[2]), \n",
    "               stateful=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27640 samples, validate on 9214 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_X, y_train, validation_data=(test_X, y_test), \n",
    "              epochs=10, batch_size=batch_size, verbose=1, shuffle=False)\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
